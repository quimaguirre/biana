
																			##################
																			BIANA RELEASE 2017
																			##################
----------
OBJECTIVES
----------

Release a new version of BIANA, containing the updated data of the databases of the previous release, but include data from new databases in order to:

- Integrate more and more diverse interactomic data, in order to improve the analysis of programs that use BIANA such as DIANA, or the TransQST project
- Include different types of data from the previous releases, such as data from drug-drug interactions, drug-target interactions, drug-disease interactions, drug-side-effect interactions, etc.
- Review the current parsers used for the previous releases, and create new parsers for the new databases
- Provide new scripts and tools for the analysis of the new type of interactions, and improve the current ones
- Update a new and more descriptive documentation/web at the same time that the program is updated

START: 30 of November of 2016
-----
EXPECTED END: January/February of 2017
------------
CURRENT BIANA DATABASES:
-----------------------
- BioGRID
- DIP
- GO
- IPI
- MINT
- PSI-MI-OBO
- Reactome
- SCOP
- Taxonomy
- UniProt
- COG 2014:   /home/quim/BIANA/biana/BianaParser/cogParser_2014.py
- HGNC:     /home/quim/BIANA/biana/BianaParser/hgncParser_2016.py
- IREFINDEX:  /home/quim/BIANA/biana/BianaParser/iRefIndexParser_2016.py
- INTACT:   /home/quim/BIANA/biana/BianaParser/psi_Mi25Parser_intact.py
- HPRD:     /home/quim/BIANA/biana/BianaParser/psi_Mi25Parser_HPRD.py

NEW DATABASES:
-------------
- HPRD (fix it)
- INTACT (fix it)
- STRING
- DrugBank
- DCDB
- SIDER
- STITCH
- FAERS
- OMIM
- DisGeNet
- The Human Protein Atlas
- NCBI Gene
- OpenTargets?
- ChEMBL?


-------
OUTLINE
-------

1) Creation of the new BIANA database
2) Add changes to GitHub
3) Parsing of STRING
4) Parsing of Uniprot
5) Parsing of DisGeNET
6) Parsing of HPRD
7) Parsing of IntAct
8) Parsing of BioGRID
9) Parsing of DIP
10) Parsing of MIPS Mammalian PPI Database
11) Parsing of MINT
12) Parsing of Reactome
13) Parsing of GO
14) Parsing of PSI-MI-OBO
15) Parsing of Taxonomy
16) Parsing of IPI
17) Parsing of COG 2014
18) Parsing of HGNC
19) Parsing of iRefIndex
20) Parsing of SCOP
21) Parsing of DrugBank
22)
XX) Parsing summary


-------------------------------------
1. CREATION OF THE NEW BIANA DATABASE
-------------------------------------

1.1) Go to scripts/administration,and run the "create_new_biana_database.py" script:

$> cd /home/quim/BIANA/scripts/administration
$> /soft/devel/python-2.7/bin/python create_new_biana_database.py -n BIANA_JAN_2017 -s localhost -u quim -d BIANA new version from January of 2017

NOTE: Using this script "create_new_biana_database.py", we will probably be able to find where we have to add the creation of the tables from the new database, so that if anyone installs the database, the new tables are already created.

If go to mysql, we can already see the new database installed:

$> mysql
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| BIANA_2016         |
| BIANA_JAN_2017     |
| mysql              |
| test               |
+--------------------+

I will also create a test_2017 database where the proofs will be done:
$> /soft/devel/python-2.7/bin/python create_new_biana_database.py -n test_2017 -s localhost -u quim -d "tests of the new 2017 BIANA version (not the official)"

If we need to reset this database we can use this:
$> /soft/devel/python-2.7/bin/python reset_biana_database.py -n test_2017 -s localhost -u quim


------------------------
2. ADD CHANGES TO GITHUB
------------------------

2.1) Work with GitHub

I will start to add the changes of the parsers and anything related with BIANA to the repository in GitHub. To do so, I have created a fork of the Emre repository in my account:

- Go to the repository on github: https://github.com/emreg00/biana
- Click the “Fork” button at the top right.

Now I have my own copy of that repository in my github account.

Now, I will clone my copy of the repository in my local computer, in concrete in a folder called "biana_git":

$> git init
$> git clone https://github.com/quimaguirre/biana.git biana_git

Now, I have a local copy of my version of that repository.

Change into that project directory (biana_git):

$> cd biana_git

Add a connection to the original owner’s repository.

$> git remote add emre https://github.com/emreg00/biana

To check this remote add set up:

$> git remote -v
emre	https://github.com/emreg00/biana (fetch)
emre	https://github.com/emreg00/biana (push)
origin	https://github.com/quimaguirre/biana.git (fetch)
origin	https://github.com/quimaguirre/biana.git (push)


2.2) Addition of the manual

I have added the manual documents in the repository, so that I can keep track of the changes.

I have copied all the documents of the manual in a folder inside "biana_git" called manual.

Then, I have done the following commands:

$> cd /home/quim/biana_git
$> git add manual
$> git commit -m "Addition of the BIANA manual to keep track of the changes on it"
$> git push -u origin master

Now, whenever I do a change in the manual, I have to do the following commands:

$> cd /home/quim/biana_git
$> git add manual
$> git commit -m "Addition of the BIANA manual to keep track of the changes on it"
$> git push -u origin master


2.3) Addition of the notes

I will save this file (outline_biana_2017.txt) in github as well to have a track during a certain time:

$> cd /home/quim/biana_git
$> cp /home/quim/project/outline_biana_2017.txt .
$> git add outline_biana_2017.txt
$> git commit -m "Addition of the BIANA 2017 release notes"
$> git push -u origin master



--------------------
3. PARSING OF STRING
--------------------

The purpose is to: 
- Download the database
- Analyse the data
- Create a new parser from the old parser of STRING ("stringParserV9.py")


3.1) Download the database

We need to go to the web: http://string-db.org/cgi/download.pl
There, we have to download the files:
- protein.links.detailed.v10.txt.gz (16.7 Gb)
- protein.sequences.v10.fa.gz (2.2 Gb)
- protein.aliases.v10.txt.gz (636.2 Mb)


3.2) Analyse the data

We can create a script which reads the compressed files in order to inspect the data. This script is "home/quim/BIANA/scripts/administration/read_gzip.py"

The file "protein.links.detailed.v10.txt.gz" has the following overview:

protein1 protein2 neighborhood fusion cooccurence coexpression experimental database textmining combined_score
394.NGR_c00010 394.NGR_c00020 522 0 0 0 0 0 0 522
394.NGR_c00010 394.NGR_c00030 522 0 0 0 0 0 0 522
394.NGR_c00010 394.NGR_c00040 402 0 0 0 0 0 0 402
394.NGR_c00010 394.NGR_c00050 388 0 0 0 0 0 0 388
394.NGR_c00010 394.NGR_c00060 281 0 0 0 0 0 0 281
394.NGR_c00010 394.NGR_c00110 71 0 0 0 0 0 309 330
394.NGR_c00010 394.NGR_c00120 0 0 0 0 0 0 472 472
394.NGR_c00010 394.NGR_c00170 0 0 0 0 0 0 261 261
394.NGR_c00010 394.NGR_c00200 0 0 203 0 0 0 0 203
394.NGR_c00010 394.NGR_c00220 0 0 0 0 420 0 208 521
394.NGR_c00010 394.NGR_c00280 0 0 0 0 84 0 211 246
394.NGR_c00010 394.NGR_c00300 0 0 0 0 0 0 200 200
394.NGR_c00010 394.NGR_c00310 0 0 166 0 0 0 764 794
394.NGR_c00010 394.NGR_c00350 0 0 0 0 0 0 211 211
394.NGR_c00010 394.NGR_c00380 0 0 200 0 0 0 0 200
394.NGR_c00010 394.NGR_c00430 0 0 0 0 0 0 202 202

The file "protein.sequences.v10.fa.gz" has the following overview:

>394.NGR_c00010 (Sinorhizobium fredii NGR234)
MRHDALFERVSARLKAQVGPDVFASWFGRLKLHSVSKSVVRLSVPTTFLKSWINNRYLELITSLFQQEDGEILKVEILVR
TATRGQRPAVHEEAVAAAAEPAAAAPVRRAASPQPVAAAAATVAASAKPVQAPLFGSPLDQRYNFESFVEGSSNRVALAA
ARTIAEAGAGAVRFNPLFIHSSVGLGKTHLLQAIALAALQSARAPRVVYLTAEYFMWRFATAIRDNDALSLKESLRNIDL
LVIDDMQFLQGKSIQHEFCHLLNMLLDSAKQVVVAADRAPWELESLDSRVRSRLQGGVAIEMEGPDYDMRLEMLKRRLDT
ARQDDTSLDIPQEILSHVARSVTASGRELEGAFNQLLFRRSFEPQLSIERVDELLGHLVNAGEPRRVRIEDIQRIVAKHY
NVSRQELVSNRRTRVIVKPRQIAMYLSKTLTPRSFPEIGRRFGGRDHTTVLHAVRKIEELISGDTKLSHEIELLKRLINE
>394.NGR_c00020 (Sinorhizobium fredii NGR234)
MLYAVLCYNTEDVTSAWTKEQDDKVMRDLTAVQRKYVEAGKLGPVARLLPTTAATTLRHRPGETVVIDGPFAETKEQLLG
FYLIDCASLDEALEFARELSAANPAAGSYEIRPLSLYKPGELAP
>394.NGR_c00030 (Sinorhizobium fredii NGR234)
MTDTAWIDLALVSARPQAMGALLRYFRNLDLAEEAFQEACIRALKTWPTNGPPRDPAAWLIFVGRNSGIDRVRRQSRETA
LPPEELLSDIEDRESELADRLDGAHYRDDILRLLFVCSNPVLPATQQIALALRIVSGLSVKQIARAFLVGEAAMEQRITR
AKARVTAAGIPFETPDASERAERLAAVAMMIYLVFNEGYSAMNGPEGVSADLCDEAIRLARLLLRLFPAEPEIMGLTALL
LLQHSRARARFDAHGAIVLLEDQDRQLWSLPMITEALAMIDKAMRHRRPGPYQVQAAIAALHARAERSEQTDWEEIELLY
RALERLQPSPVVTLNRAVAVSKRDGPEAALALVEPLADRLSGYFYFHGLRGGLLKQMGRAREARVAFDRAIALATNAAEA
AYIRKQLDHLAGEAGASHLHEDQQ
>394.NGR_c00040 (Sinorhizobium fredii NGR234)
MTAATDTRPADERDLVLIRLIDAPREKVYRAFTDPELLKQWFAPLPWTITEAELDVRPGGTNRFVMRSPEGELYPNQGVY
LEVVPNEKLVMSDAYTEAWTPSEKPFMTAILTFEEEGGKTRYTARARHWSTADREAHEKMGFHEGWGQCADQLAALVAKL


And the file "protein.aliases.v10.txt.gz" looks as follows:

## string_protein_id ## alias ## source ##
3711.Bra027507.1-P	1,2-dihydroxy-3-keto-5-methylthiopentene dioxygenase	BLAST_UniProt_DE
3711.Bra035994.1-P	1,2-dihydroxy-3-keto-5-methylthiopentene dioxygenase	BLAST_UniProt_DE
3711.Bra036884.1-P	1,2-dihydroxy-3-keto-5-methylthiopentene dioxygenase	BLAST_UniProt_DE
3711.Bra007313.1-P	1,3 GLUCAN-BR-1	BLAST_UniProt_GN
3711.Bra007314.1-P	1,3 GLUCAN-BR-2	BLAST_UniProt_GN
3711.Bra039006.1-P	1-aminocyclopropane-1-carboxylate oxidase	BLAST_UniProt_DE
3711.Bra035236.1-P	1-aminocyclopropane-1-carboxylic acid synthase	BLAST_UniProt_DE
3711.Bra040490.1-P	11272149	BLAST_UniProt_DR_GeneID
3711.Bra006038.1-P	117M18_1	BLAST_UniProt_DE BLAST_UniProt_GN
3711.Bra006048.1-P	117M18_10	BLAST_UniProt_DE BLAST_UniProt_GN
3711.Bra010851.1-P	117M18_11	BLAST_UniProt_DE BLAST_UniProt_GN
3711.Bra006050.1-P	117M18_12	BLAST_UniProt_DE BLAST_UniProt_GN
3711.Bra006051.1-P	117M18_13	BLAST_UniProt_DE
3711.Bra006052.1-P	117M18_14	BLAST_UniProt_DE BLAST_UniProt_GN
3711.Bra006053.1-P	117M18_15	BLAST_UniProt_GN

3.3) Fix the parser and parse

I have checked the "stringParserV9.py" in "/home/quim/BIANA/biana/BianaParser/".
There are some changes when parsing the Aliases file "protein.aliases.v10.txt.gz". For example, there was a TaxID value in the previous version that is not in the current.
Therefore, I downloaded the Aliases file from version 9.0 in order to see better the differences. This is an overview:

## species_ncbi_taxon_id ## protein_id ## alias ## source ##
3218	JGI170596	(2R)-phospho-3-sulfolactate synthase-like protein	BLAST_UniProt_DE
3218	JGI170596	(2R)-phospho-3-sulfolactate synthase-related protein	BLAST_UniProt_DE
3218	JGI218018	1,4-fuc-t	BLAST_UniProt_GN
3218	JGI105028	1-deoxyxylulose 5-phosphate synthase	BLAST_UniProt_DE
3218	JGI137710	1-deoxyxylulose 5-phosphate synthase	BLAST_UniProt_DE
3218	JGI150209	2-C-methyl-D-erythritol 2,4-cyclodiphosphate synthase	BLAST_UniProt_DE
3218	JGI105737	26S proteasome regulatory complex, ATPase RPT4	BLAST_UniProt_DE
3218	JGI203204	26S proteasome regulatory complex, ATPase RPT4	BLAST_UniProt_DE
3218	JGI213701	26S proteasome regulatory complex, ATPase RPT4	BLAST_UniProt_DE
3218	JGI158251	26S proteasome regulatory complex, ATPase RPT6	BLAST_UniProt_DE
3218	JGI170441	26S proteasome regulatory complex, ATPase RPT6	BLAST_UniProt_DE
3218	JGI115152	3-isopropylmalate dehydrogenase	BLAST_UniProt_DE
3218	JGI234493	3-phosphoshikimate 1-carboxyvinyltransferase	BLAST_UniProt_DE

The main change is the TaxID column, so we have to change this part of the parser. 
The fact is that in the old version of STRING, tax and id were in different fields and they were joined to enter them in the database.
For example: If a protein has TaxID 3218 and protein_id JGI69490 it is joined as --> 3218.JGI69490
In the new version, they are already joined, the proteins are in this format: 3711.Bra006048.1-P. Therefore, we do not have to join taxid and protein id.

We will create a new parser called "stringParserV10.py":
- I changed line 11 to:     name = "stringV10"
- I changed line 46 to:     default_script_name = "stringParserV10.py",
- I changed lines 303-307 to line 303:     id_word = words[0][:biana_globals.MAX_ALIAS_SIZE]
- I changed line 304 to:     alias = words[1].replace("\"", "").strip()[:biana_globals.MAX_ALIAS_SIZE] #.strip("\"")
- I changed line 305 to:     source_list = words[2].split()

And now, I will try the new parser:

$> /soft/devel/python-2.7/bin/python parse_database.py stringV10 --input-identifier="/home/quim/Databases/string/" --biana-dbname="test_2017" --biana-dbuser="quim" --biana-dbhost="localhost" --time-control --database-name="STRING" --database-version="v10"

And finally I modify the new manual: "/home/quim/new_BIANA/new_manual/biana_reference_manual_v1.4.pdf"

CHECK PARSING TIME AND ADD IT INTO MANUAL!!
- 99200000 alias done in 4075.57691312 seconds
- 

Everything seems to work. The only thing that worries me is that all the interactions are considered as "functional association", and there could be "physical" interactions (in BIANA they are called "interaction") that are not considered and are called functional associations as well.
There are the following types of relations in BIANA: enum('alignment','backward_reaction','cluster','complex','cooperation','forward_reaction','functional_association','homology','interaction','no_interaction','pathway','reaction','regulation')
The interaction types in STRING are compiled in the file protein.actions.v10.txt.gz (3 Gb). I have checked this file, and it basically describes the "mode" in which the two proteins interact (activation, binding, catalysis, reactio, ptmod...) and the "action" (activation, inhibition, 0). 
Talking with Emre, he says that the interactions are mainly functional, although some of them are physical. I think that it may be correct to classify them as functional, as they are interactions obtained from an score.

3.4) Parse using Gaudi

Find a way to parse databases using Gaudi

source /usr/local/sge/default/common/settings.sh



---------------------
4. PARSING OF UNIPROT
---------------------

The purpose is to: 
- Analyse the data of Uniprot
- Check the parsers of Uniprot
- Parse Uniprot Swissprot and the old version of Uniprot Trembl

4.1) Download Uniprot

We can download Uniprot Swissprot at this website: http://www.uniprot.org/downloads
It can also be found here: ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/
We have to click at Swissprot "text" option (519 MB).

As Uniprot Trembl is very big (40 GB), we will download the 2013 version. We go to the FTP site: ftp://ftp.uniprot.org/pub/databases/uniprot/
And we dowload the 2013_03 release (13 GB).

4.2) Analyse the data

We will analyse the Swissprot data using the script "read_gzip". This would be an example of one entry in Swissprot:

ID   001R_FRG3G              Reviewed;         256 AA.
AC   Q6GZX4;
DT   28-JUN-2011, integrated into UniProtKB/Swiss-Prot.
DT   19-JUL-2004, sequence version 1.
DT   17-FEB-2016, entry version 31.
DE   RecName: Full=Putative transcription factor 001R;
GN   ORFNames=FV3-001R;
OS   Frog virus 3 (isolate Goorha) (FV-3).
OC   Viruses; dsDNA viruses, no RNA stage; Iridoviridae; Ranavirus.
OX   NCBI_TaxID=654924;
OH   NCBI_TaxID=8295; Ambystoma (mole salamanders).
OH   NCBI_TaxID=30343; Hyla versicolor (chameleon treefrog).
OH   NCBI_TaxID=8404; Lithobates pipiens (Northern leopard frog) (Rana pipiens).
OH   NCBI_TaxID=8316; Notophthalmus viridescens (Eastern newt) (Triturus viridescens).
OH   NCBI_TaxID=45438; Rana sylvatica (Wood frog).
RN   [1]
RP   NUCLEOTIDE SEQUENCE [LARGE SCALE GENOMIC DNA].
RX   PubMed=15165820; DOI=10.1016/j.virol.2004.02.019;
RA   Tan W.G., Barkman T.J., Gregory Chinchar V., Essani K.;
RT   "Comparative genomic analyses of frog virus 3, type species of the
RT   genus Ranavirus (family Iridoviridae).";
RL   Virology 323:70-84(2004).
CC   -!- FUNCTION: Transcription activation. {ECO:0000305}.
DR   EMBL; AY548484; AAT09660.1; -; Genomic_DNA.
DR   RefSeq; YP_031579.1; NC_005946.1.
DR   ProteinModelPortal; Q6GZX4; -.
DR   SwissPalm; Q6GZX4; -.
DR   GeneID; 2947773; -.
DR   KEGG; vg:2947773; -.
DR   Proteomes; UP000008770; Genome.
DR   GO; GO:0006355; P:regulation of transcription, DNA-templated; IEA:UniProtKB-KW.
DR   GO; GO:0046782; P:regulation of viral transcription; IEA:InterPro.
DR   GO; GO:0006351; P:transcription, DNA-templated; IEA:UniProtKB-KW.
DR   InterPro; IPR007031; Poxvirus_VLTF3.
DR   Pfam; PF04947; Pox_VLTF3; 1.
PE   4: Predicted;
KW   Activator; Complete proteome; Reference proteome; Transcription;
KW   Transcription regulation.
FT   CHAIN         1    256       Putative transcription factor 001R.
FT                                /FTId=PRO_0000410512.
FT   COMPBIAS     14     17       Poly-Arg.
SQ   SEQUENCE   256 AA;  29735 MW;  B4840739BF7D4121 CRC64;
MAFSAEDVLK EYDRRRRMEA LLLSLYYPND RKLLDYKEWS PPRVQVECPK APVEWNNPPS
EKGLIVGHFS GIKYKGEKAQ ASEVDVNKMC CWVSKFKDAM RRYQGIQTCK IPGKVLSDLD
AKIKAYNLTV EGVEGFVRYS RVTKQHVAAF LKELRHSKQY ENVNLIHYIL TDKRVDIQHL
EKDLVKDFKA LVESAHRMRQ GHMINVKYIL YQLLKKHGHG PDGPDILTVK TGSKGVLYDD
SFRKIYTDLG WKFTPL
//

We will do the same with Trembl. This is an example of an entry:

ID   U2E2C9_9EURY            Unreviewed;       277 AA.
AC   U2E2C9;
DT   13-NOV-2013, integrated into UniProtKB/TrEMBL.
DT   13-NOV-2013, sequence version 1.
DT   16-MAR-2016, entry version 9.
DE   SubName: Full=Uncharacterized protein {ECO:0000313|EMBL:ERJ06136.1};
GN   ORFNames=HLRTI_001755 {ECO:0000313|EMBL:ERJ06136.1}, HLRTI_003224
GN   {ECO:0000313|EMBL:ERJ04821.1};
OS   Halorhabdus tiamatea SARL4B.
OC   Archaea; Euryarchaeota; Halobacteria; Halobacteriales;
OC   Halobacteriaceae; Halorhabdus.
OX   NCBI_TaxID=1033806 {ECO:0000313|EMBL:ERJ06136.1};
RN   [1] {ECO:0000313|EMBL:ERJ06136.1}
RP   NUCLEOTIDE SEQUENCE.
RC   STRAIN=SARL4B {ECO:0000313|EMBL:ERJ06136.1};
RX   PubMed=21705593; DOI=10.1128/JB.05462-11;
RA   Antunes A., Alam I., Bajic V.B., Stingl U.;
RT   "Genome sequence of Halorhabdus tiamatea, the first archaeon isolated
RT   from a deep-sea anoxic brine lake.";
RL   J. Bacteriol. 193:4553-4554(2011).
RN   [2] {ECO:0000313|EMBL:ERJ06136.1}
RP   NUCLEOTIDE SEQUENCE.
RC   STRAIN=SARL4B {ECO:0000313|EMBL:ERJ06136.1};
RX   PubMed=24324765;
RA   Alam I., Antunes A., Kamau A.A., Ba Alawi W., Kalkatawi M., Stingl U.,
RA   Bajic V.B.;
RT   "INDIGO - INtegrated Data Warehouse of MIcrobial GenOmes with Examples
RT   from the Red Sea Extremophiles.";
RL   PLoS ONE 8:E82210-E82210(2013).
CC   -!- CAUTION: The sequence shown here is derived from an
CC       EMBL/GenBank/DDBJ whole genome shotgun (WGS) entry which is
CC       preliminary data. {ECO:0000313|EMBL:ERJ06136.1}.
CC   -----------------------------------------------------------------------
CC   Copyrighted by the UniProt Consortium, see http://www.uniprot.org/terms
CC   Distributed under the Creative Commons Attribution-NoDerivs License
CC   -----------------------------------------------------------------------
DR   EMBL; AFNT02000055; ERJ04821.1; -; Genomic_DNA.
DR   EMBL; AFNT02000019; ERJ06136.1; -; Genomic_DNA.
DR   STRING; 1033806.HLRTI_10481; -.
DR   EnsemblBacteria; ERJ04821; ERJ04821; HLRTI_003224.
DR   EnsemblBacteria; ERJ06136; ERJ06136; HLRTI_001755.
DR   eggNOG; arCOG06243; Archaea.
DR   eggNOG; ENOG410Z8WP; LUCA.
PE   4: Predicted;
SQ   SEQUENCE   277 AA;  29812 MW;  35B59E66091CE5B3 CRC64;
MTWEYIAYVR AYSPELGSIN STEKSISFVI DRERERVRTF MRITAQPCGM SSQPDRSDLP
EVLRELTSSL VRLRRDLRSD QRSGGRGLDR LLRLTTDVTI PATILVLETN IRALRLLQRT
LRIVDGSETA EESRTTAGED VASVGRSVVD RLDDALADVQ TAVEGDVDSR TRDHLEDARD
LNRKLEARLD ELSEGAAAPG GEEESTSDDR GAAVDVEAEL RSIKDQHGDS GGGGDSDEGD
AAGGNDSDEG GADGRNDSDE GGAADGTDQG EGDGSDE
//

The format is the same. The only thing that changes is that Swissprot proteins are reviewed and Trembl are unreviewed.


4.3) Check the parser

We will check the parser "uniprotParser.py", which works the same for Trembl and Swissprot.

It seems to have everything correct. The only problem is how to check if there are more sources, for example. In this page, we can see the cross-references of Uniprot: http://www.uniprot.org/docs/dbxref
Here the database is very well explained, specially the cross-references: http://web.expasy.org/docs/userman.html

The fact is that there are lots of cross-references which are missed and should be included. At least, all the cross-references from BIANA current external databases and the ones from the new databases.
Therefore, we should check which cross-references of interest are not in the old parser and include them in a new Uniprot parser. And also, consider how to include them. It is not a trivial job, and it will take its time.


4.4) Different types of lines and how the parser works with them

- ID: Identification line 
	ID   EntryName Status; SequenceLength.
	ID   CYC_BOVIN               Reviewed;         104 AA.

	PARSER: If the status is reviewed, it knows that it comes from Swissprot and introduces the entryname at UniprotEntry table as 'unique'

- AC: Accession number line
	(Semicolons separate the accession numbers and a semicolon terminates the list. If necessary, more than one AC line can be used)
	AC   AC_number_1;[ AC_number_2;]...[ AC_number_N;]
	AC   Q92892; Q92893; Q92894; Q92895; Q93053; Q96KU9; Q96KV0; Q96KV1;
	AC   Q99605;

	PARSER: It obtains the list of accessions by spliting by ';'. 
	Then, if it is the first accession in the list, it is classified as 'unique'.
	If it is not the first, it is classified as 'previous'.

- DT: Date of creation and last modification of the database entry
	DT   DD-MMM-YYYY, integrated into UniProtKB/database_name.
	DT   DD-MMM-YYYY, sequence version x.
	DT   DD-MMM-YYYY, entry version x.
	DT   01-OCT-1996, integrated into UniProtKB/Swiss-Prot.
	DT   01-OCT-1996, sequence version 1.
	DT   07-FEB-2006, entry version 49.

	PARSER: Not processed

- DE: Descriptive information about the sequence stored
	- In SwissProt: 
		The description always starts with the recommended name (RecName) of the protein. 
		Alternative names (AltName) are indicated thereafter.
		The DE line contains 3 categories (RecName/AltName/SubName), as well as several subcategories, of protein names:
			- RecName: The name recommended by the UniProt consortium.
				- Full
				- Short
				- EC
			- AltName: A synonym of the recommended name.
				- Full
				- Short
				- EC
			- SubName: A name provided by the submitter of the underlying nucleotide sequence.
				- Full
				- EC
		Examples:
			DE   RecName: Full=Granulocyte colony-stimulating factor;
			DE            Short=G-CSF;
			DE   AltName: Full=Pluripoietin;
			DE   AltName: Full=Filgrastim;
			DE   AltName: Full=Lenograstim;
			DE   Flags: Precursor;
		A block of DE lines may further contain multiple Includes: and/or Contains: sections and a separate field Flags: to indicate whether the protein sequence is a precursor or a fragment:
			- Includes:	0-n 	A block of protein names as described in the table above.
			- Contains:	0-n 	A block of protein names as described in the table above.
			- Flags:	0-1 	Precursor and/or Fragment or Fragments
		If a protein is known to be cleaved into multiple functional components, the description starts with the name of the precursor protein, followed by 'Contains:' section(s). Each individual component is described in a separate 'Contains:' section Alternative names (AltName) are allowed for each individual component.
		If a protein is known to include multiple functional domains each of which is described by a different name, the description starts with the name of the overall protein, followed by 'Includes:' section(s). All the domains are listed in a separate 'Includes:' section. Alternative names (AltName) are allowed for each individual domain.
		When the mature form of a protein is derived by processing of a precursor, we indicate this fact using the Flag 'Precursor'; in such cases the sequence displayed does not correspond to the mature form of the protein.

	PARSER: First, it detects the DE lines and joins all the DE lines of one entry in one string. It introduces this string into the Description table
	Then, it finds the RecName's in this string and adds them in the Name table as 'unique'.
	It also finds all the AltName's in this string and adds them in the table Name as 'synonym'.
	It also finds the Short names and adds them in the table Name as 'unique'.

	PROBLEM: It does not detects well the terms after "Contains:" and "Includes:" sections, and it makes the table "Name" be not well parsed.
	We should change the parser in order to skip the terms after "Contains:" and "Includes:".
	Finally, I may leave it like this, because it may be useful for text-mining approaches.


- GN: Gene name line. Indicates the name(s) of the gene(s) that code for the stored protein sequence. Contains three types of information:
	- Gene names (a.k.a gene symbols). The name(s) used to represent a gene
	- Ordered locus names (a.k.a. OLN, ORF numbers, CDS numbers or Gene numbers). A name used to represent an ORF in a completely sequenced genome or chromosome.
	- ORF names (a.k.a. sequencing names or contig names or temporary ORFNames). A name temporarily attributed by a sequencing project to an open reading frame.
		GN   Name=<name>; Synonyms=<name1>[, <name2>...]; OrderedLocusNames=<name1>[, <name2>...];
		GN   ORFNames=<name1>[, <name2>...];
	If there is more than one gene, GN line blocks for the different genes are separated by the following line:
	    GN   and
    Example:
		GN   Name=Jon99Cii; Synonyms=SER1, SER5, Ser99Da; ORFNames=CG7877;
		GN   and
		GN   Name=Jon99Ciii; Synonyms=SER2, SER5, Ser99Db; ORFNames=CG15519;

	PARSER: First it finds the "GN" line.
	It finds the "Name=" and adds them as geneSymbol of type 'unique'.
	It finds the "ORFNames=" and adds them as ORFName of type 'alias'.
	It finds the "Synonyms=" and adds them as geneSymbol of type 'synonym'
	It finds the "OrderedLocusNames=" and adds them as OrderedLocusName of type 'alias'

- OS: Organism Species line
	OS   Escherichia coli.
	OS   Solanum melongena (Eggplant) (Aubergine).
	OS   Rous sarcoma virus (strain Schmidt-Ruppin A) (RSV-SRA) (Avian leukosis
	OS   virus-RSA).

	PARSER: Not processed.

- OG: Organelle line. Indicates if the gene coding for a protein originates from mitochondria, a plastid, a nucleomorph or a plasmid.
	OG   Hydrogenosome.
	OG   Mitochondrion.
	OG   Nucleomorph.
	OG   Plasmid name.
	OG   Plastid.
	OG   Plastid; Apicoplast.

	PARSER: Not processed.

- OC: Organism Classification, contains the taxonomic classification of the source organism.
	OC   Node[; Node...].
	OC   Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;
	OC   Mammalia; Eutheria; Euarchontoglires; Primates; Catarrhini; Hominidae;
	OC   Homo.

	PARSER: Not processed.

- OX: Organism taxonomy cross-reference: indicate the identifier of a specific organism in a taxonomic database
	OX   NCBI_TaxID=9606;

	PARSER: Adds the code at the TaxID table.

- OH: Organism Host: appears only in viral entries. It indicates the host organism(s) that are susceptible to be infected by a virus.
	OH   NCBI_TaxID=TaxID; HostName.
	OH   NCBI_TaxID=9536; Cercopithecus hamlyni (Owl-faced monkey) (Hamlyn's monkey).

	PARSER: Not processed.

- The reference (RN, RP, RC, RX, RG, RA, RT, RL) lines
	These lines comprise the literature citations. The citations indicate the sources from which the data has been abstracted. 
	The reference lines for a given citation occur in a block, and are always in the order RN, RP, RC, RX, RG, RA, RT and RL.
	Within each such reference block, the RN line occurs once, the RC, RX and RT lines occur zero or more times, and the RP, RG/RA and RL lines occur one or more times.
	- RN: Reference Number
	- RP: Reference Position
	- RC: Reference Comment
	- RX: Reference cross-reference
	- RG: Reference Group
	- RA: Reference Author
	- RT: Reference Title
	- RL: Reference Line
		RN   [1]
		RP   NUCLEOTIDE SEQUENCE [MRNA] (ISOFORMS A AND C), FUNCTION, INTERACTION
		RP   WITH PKC-3, SUBCELLULAR LOCATION, TISSUE SPECIFICITY, DEVELOPMENTAL
		RP   STAGE, AND MUTAGENESIS OF PHE-175 AND PHE-221.
		RC   STRAIN=Bristol N2;
		RX   PubMed=11134024; DOI=10.1074/jbc.M008990200;
		RA   Zhang L., Wu S.-L., Rubin C.S.;
		RT   "A novel adapter protein employs a phosphotyrosine binding domain and
		RT   exceptionally basic N-terminal domains to capture and localize an
		RT   atypical protein kinase C: characterization of Caenorhabditis elegans
		RT   C kinase adapter 1, a protein that avidly binds protein kinase C3.";
		RL   J. Biol. Chem. 276:10463-10475(2001).

	PARSER: Not processed.

- CC: They are free text comments on the entry, and are used to convey any useful information
	CC   -!- ALLERGEN: Causes an allergic reaction in human. Binds to IgE.
	CC       Partially heat-labile allergen that may cause both respiratory and
	CC       food-allergy symptoms in patients with the bird-egg syndrome.

	CC   -!- BIOTECHNOLOGY: Used in the food industry for high temperature
	CC       liquefaction of starch-containing mashes and in the detergent
	CC       industry to remove starch. Sold under the name Termamyl by
	CC       Novozymes.

	PARSER: It finds if it is the first line of the comment or not.
	If it is the first line, it looks for three types of comments:
	- SUBCELLULAR LOCATION
	- FUNCTION
	- DISEASE
	If it is not the first line, it appends this line with the previous ones.
	The function comments are added at the "Function" table, the disease at the "Disease" table, and the subcellular at the "subcellularLocation" table.

	COMMENT : The table "externalEntityDisease" contains the whole commentary of the swissprot "DISEASE" term.
	-------   This is fine because the gene-disease associations are not so easy to define, and usually we use 
       		  text-mining approaches to search for these associations.
       		  In fact, Guildify uses a text-mining approach in BIANA, so that if we search a disease term such as
			  "Alzheimer", it will perform a text-mining search in BIANA and it will extract commentaries such as
          	  these ones.
          	  The same happens with the tables "externalEntityFunction" and "externalEntitySubcellularLocation". They
          	  are tables which are only dedicated to the commentaries in Uniprot for Function and SubcellularLocation,
          	  and that are useful for text mining approaches.

	ADD TO PARSER: Think about including these fields:
	- TISSUE SPECIFICITY
	    CC   -!- TISSUE SPECIFICITY: Expressed at high levels in brain and ovary.
    	CC       Lower levels in small intestine. In brain regions, detected in all
    	CC       regions tested. Highest levels in the cerebellum and cerebral
	    CC       cortex.
	- INTERACTION:
		CC   -!- INTERACTION:
		CC       Self; NbExp=1; IntAct=EBI-123485, EBI-123485;
		CC       Q9W158:CG4612; NbExp=1; IntAct=EBI-123485, EBI-89895;
		CC       Q9VYI0:fne; NbExp=1; IntAct=EBI-123485, EBI-126770;
	- PATHWAY:
		CC   -!- PATHWAY: Cofactor biosynthesis; porphyrin biosynthesis; 5-
		CC       aminolevulinate from L-glutamyl-tRNA(Glu): step 2/2.

- DR: Database cross-Reference lines

	PARSER: It has different regex for each kind of cross-Reference and adds them at their corresponding table.

- PE: Protein existence line. Gives indication on the evidences that we currently have for the existence of a protein:
	- 1: Evidence at protein level
	- 2: Evidence at transcript level
	- 3: Inferred from homology
	- 4: Predicted
	- 5: Uncertain
	PE   1: Evidence at protein level;

	PARSER: Not processed.

- KW: Keyword line
	KW   Keyword[; Keyword...].
	KW   3D-structure; Alternative splicing; Alzheimer disease; Amyloid;

	PARSER: It finds the KW line, splits the keyboards by ';' and adds them at the "keyword" table

- FT: Provides a precise but simple means for the annotation of the sequence data

	PARSER: Not processed.

- SQ: SeQuence header line. Marks the beginning of the sequence data and gives a quick summary of its content.
	SQ   SEQUENCE XXXX AA; XXXXX MW; XXXXXXXXXXXXXXXX CRC64;
	SQ   SEQUENCE   486 AA;  55639 MW;  D7862E867AD74383 CRC64;

	PARSER: Not processed.

  -------------------------------------------------------------------------------------------------------------------------
  Concluding remarks: I have been able to see that some of the tables that BIANA have and that are filled with Uniprot
  data (externalEntityNames, externalEntityDescription, externalEntityDisease, externalEntityKeyboards...) are also thought
  in order to implement text-mining approaches using Guildify, and I have to be careful not to delete useful information.
  -------------------------------------------------------------------------------------------------------------------------


4.5) Add new cross-references

The web http://web.expasy.org/docs/userman.html#DR_line explains the DR (Database cross-Reference) line composition:

DR   RESOURCE_ABBREVIATION; RESOURCE_IDENTIFIER; OPTIONAL_INFORMATION_1[; OPTIONAL_INFORMATION_2][; OPTIONAL_INFORMATION_3].

Where:
- Resource abbreviation: It is the abbreviated name of the referenced source
- Resource identifier: It is a pointer to a record in the reference resource
- Optional information 1/2: They provide more information for some specific databases

The list of new cross-references will be:
- EMBL ?
- BindingDB ?
- BioCyc ? (Collection of Pathway/Genome Databases)
- BioGRID
- BRENDA
- ChEMBL
- CGD? (Candida genome database)
- DIP
- DisGeNET
- DrugBank
- Ensembl (and EnsemblBacteria, EnsemblFungi, EnsemblMetazoa, EnsemblPlants, EnsemblProtists)
- FlyBase
- GeneCards?
- GeneDB
- GeneID
- GO
- HGNC
- HPA (Human Protein Atlas)
- IntAct
- InterPro
- IPI
- KEGG
- MGI
- MIM
- MINT
- OMA?
- OpenTargets?
- Orphanet?
- OrthoDB?
- PDB
- Pfam
- PIR
- PRINTS
- Prosite
- Reactome
- RefSeq
- RGD
- SGD
- STRING
- Tair
- TIGRFAMs
- UniGene
- UniPathway?
- WormBase
- WBParaSite (WormBase ParaSite (WBParaSite))
- ZFIN?

...

We can check if a cross-reference is included and how is included directly in the data using the script "check_uniprot_crossreferences.py", placed at BIANA/scripts/administration.

Now, let's analyse each new cross-reference one by one:

4.5.1) EMBL (Nucleotide sequence database of EMBL/EBI):
- Resource abbreviation: EMBL
- Resource identifier: Accession number 	Example --> CP002684
- Optional information
  - 1: Secondary accession number 			Example --> AEE29627.1
  - 2: -
  - 3: Type of sequence 					Example --> Genomic_DNA 
- Example of line:						DR   EMBL; ACCESSION_NUMBER; PROTEIN_ID; STATUS_IDENTIFIER; MOLECULE_TYPE.
				 						DR   EMBL; CP002684; AEE29627.1; -; Genomic_DNA.
										DR   EMBL; AF370519; AAK43896.1; -; mRNA.

4.5.2) BindingDB: 
- Resource abbreviation: BindingDB
- Resource identifier: UniprotAccession 	Example --> P61981
- Optional information: -
- Example of line: 						DR   BindingDB; P61981; -.
(It won't be added as it does not provide useful information)

4.5.3) BioGrid: 
- Resource abbreviation: BioGrid
- Resource identifier:  BioGrid accession	Example --> 109368
- Optional information: number of interactions
- Example of line: 						DR   BioGrid; 109368; 38.
We will not use it because we do not use BioGrid accessions

4.5.4) BRENDA (Comprehensive Enzyme Information System):
- Resource abbreviation: BRENDA
- Resource identifier:  EC number			Example --> 1.13.12.16
- Optional information: Organism code
- Example of line: 						DR   BRENDA; 1.13.12.16; 5087.
(It is not necessary because the EC accession is parsed in another line)

4.5.5) ChEMBL (A database of bioactive drug-like small molecules):
- Resource abbreviation: ChEMBL
- Resource identifier:  ChEMBL accession	Example --> CHEMBL3580495
- Optional information: -
- Example of line: 						DR   ChEMBL; CHEMBL3580495; -.

4.5.6) DIP:
- Resource abbreviation: DIP
- Resource identifier:  DIP accession	Example --> DIP-6064N
- Optional information: -
- Example of line: 						DR   DIP; DIP-6064N; -.
We need to delete the "DIP-" part in the accession --> 6064N

4.5.7) DisGeNET: 
- Resource abbreviation: DisGeNET
- Resource identifier: GeneID 			Example --> 7529
- Optional information: -
- Example of line: 						DR   DisGeNET; 7529; -.

4.5.8) DrugBank: 
- Resource abbreviation: DrugBank
- Resource identifier: DrugBank id		Example --> DB05259
- Optional information: Drug generic name for which the protein is a target
- Example of line: 						DR   DrugBank; DB05259; Glatiramer Acetate.

4.5.9) Ensembl (and EnsemblBacteria, EnsemblFungi, EnsemblMetazoa, EnsemblPlants, EnsemblProtists): 
- Resource abbreviation: Ensembl
- Resource identifier: Transcript identifier		Example --> ENST00000515571
- Optional information 1: Protein identifier		Example --> ENSP00000422374
- Optional information 2: Gene identifier 			Example --> ENSG00000074211
- Optional isoform sequence identifier (sometimes): UniprotKB isoform sequence identifier		Example --> [Q9Y2T4-3]
- Example of line: 						DR   Ensembl; ENST00000515571; ENSP00000422374; ENSG00000074211. [Q9Y2T4-3]
										DR   Ensembl; ENST00000360004; ENSP00000353099; ENSG00000196126.
										DR   EnsemblBacteria; BAI69844; BAI69844; HTH_1393.
										DR   EnsemblFungi; EAA28352; EAA28352; NCU03949.
										DR   EnsemblMetazoa; FBtr0345177; FBpp0311386; FBgn0004889. [P36872-1]
										DR   EnsemblPlants; AT5G54740.1; AT5G54740.1; AT5G54740.
										DR   EnsemblProtists; CAI76474; CAI76474; TA08425.
										DR   EnsemblProtists; EAS66939; EAS66939; DDB_G0269138.

4.5.10) FlyBase: 
- Resource abbreviation: FlyBase
- Resource identifier: FlyBase entry		Example --> FBgn0010339
- Optional information: Gene designation or "-"
- Example of line: 						DR   FlyBase; FBgn0010339; 128up.
										DR   FlyBase; FBgn0020238; 14-3-3epsilon.

4.5.11) GeneDB: 
- Resource abbreviation: GeneDB
- Resource identifier: GeneDB unique id		Example --> PKNH_1448000.1:pep
- Optional information: -
- Example of line: 						DR   GeneDB; PKNH_1448000.1:pep; -.
I will not use it because I am not sure if GDB is this database

4.5.12) GeneID:
- Resource abbreviation: GeneID
- Resource identifier: Entrez GeneID		Example --> 106444749
- Optional information: Gene designation or "-"
- Example of line: 						DR   GeneID; 106444749; -.

4.5.13) GO:
- Resource abbreviation: GO
- Resource identifier: GO identifier		Example --> GO:0045735
- Optional information 1:  1-letter abbreviation for one of the 3 ontology aspects and GO term 		Example --> C:plasma membrane
- Optional information 2:  3-character GO evidence code. It is followed by the source database from which the cross-reference was obtained, separated by a colon 		Example --> IEA:UniProtKB-SubCell
- Example of line: 						DR   GO; GO:0045735; F:nutrient reservoir activity; IEA:UniProtKB-KW.
We need to delete the "GO-" part in the identifier --> 0045735

4.5.14) HGNC:
- Resource abbreviation: HGNC
- Resource identifier: HGNC identifier		Example --> HGNC:4948
- Optional information:  Gene designation or "-" 		Example --> HLA-DRB1
- Example of line: 						DR   DR   HGNC; HGNC:4948; HLA-DRB1.
We need to delete the "HGNC-" part in the identifier --> 4948

4.5.14) HPA (Human Protein Atlas):
- Resource abbreviation: HPA
- Resource identifier: HPA accession		Example --> HPA043151
- Optional information: -
- Example of line: 						DR   HPA; HPA043151; -.
										DR   HPA; CAB003759; -.
The HPA or CAB accessions correspond to the antibodies used to support the reliability of the data
This is why one protein can have more 3 accessions, because it has 3 antibodies supporting the data:
2B1G_HUMAN
DR   HPA; CAB015400; -.
2B1G_HUMAN
DR   HPA; CAB034021; -.
2B1G_HUMAN
DR   HPA; HPA043151; -.

4.5.15) IntAct:
- Resource abbreviation: IntAct
- Resource identifier: UniProtKB accession number		Example --> P13760
- Optional information:  number of interactors
- Example of line: 						DR   IntAct; P13760; 6.
(we may not use it, because it only provides the information about the number of interactors. We already have the uniprot accession)

4.5.16) InterPro:
- Resource abbreviation: InterPro
- Resource identifier: InterPro accession		Example --> 		IPR013771
- Optional information:  Entry name 			Example -->			Trypsin/amylase_inhib
- Example of line: 						DR   InterPro; IPR013771; Trypsin/amylase_inhib.

4.5.17) IPI:
- Resource abbreviation: IPI
- Resource identifier: IPI accession			Example --> 		IPI00000005
- Optional information: -
- Example of line: 						DR   IPI; IPI00000005; -.
(IPI is now closed, so it makes no sense to add it)

4.5.18) KEGG: 
- Resource abbreviation: KEGG
- Resource identifier:  KeggGene accession		Example --> rcu:8280733
- Optional information: -
- Example of line: 						DR   KEGG; rcu:8280733; -.
(in BIANA_MARCH_2013 it is classified as KeggGene directly)

4.5.19) MGI:
- Resource abbreviation: MGI
- Resource identifier:  MGI accession					Example --> MGI:2442660
- Optional information: Gene designation or "-" 		Example --> Ppp2r2c
- Example of line: 						DR   MGI; MGI:2442660; Ppp2r2c.
We need to delete the "MGI-" part in the identifier --> 2442660

4.5.20) MIM:
- Resource abbreviation: MIM
- Resource identifier:  MIM accession					Example --> 142857
- Optional information: This field distinguishes between MIM "gene" and "phenotype" entries. Note that some MIM entries describe both a gene and a phenotype. In such a case, this field indicates "gene+phenotype"
														Example --> gene
- Example of line: 						DR   MIM; 142857; gene.

4.5.21) MINT:
- Resource abbreviation: MINT
- Resource identifier:  MINT accession					Example --> MINT-4083947
- Optional information: -
- Example of line: 						DR   MINT; MINT-4083947; -.
(we may not use it because MINT is not functional anymore)

4.5.22) OMA (Method and database for the inference of orthologs among complete genomes):
- Resource abbreviation: OMA
- Resource identifier:  OMA group fingerprint					Example --> WIRKRAQ
- Optional information: -
- Example of line: 						DR   OMA; WIRKRAQ; -.

4.5.23) OpenTargets (Target Validation Platform):
- Resource abbreviation: OpenTargets
- Resource identifier:  Ensembl code					Example --> ENSG00000196126
- Optional information: -
- Example of line: 						DR   OpenTargets; ENSG00000196126; -.
(Interesting database to add, showing a score for the relation between a target and a disease)

4.5.24) Orphanet (a database dedicated to information on rare diseases and orphan drugs):
- Resource abbreviation: Orphanet
- Resource identifier:  ORPHA identifier of the disease									Example --> 536
- Optional information: The name of the disease caused by defects in the protein 		Example --> Systemic lupus erythematosus
- Example of lines (for 2B11_HUMAN):	DR   Orphanet; 536; Systemic lupus erythematosus.
										DR   Orphanet; 284130; Rheumatoid arthritis.

4.5.25) OrthoDB (Database of Orthologous Groups):
- Resource abbreviation: OrthoDB
- Resource identifier: OrthoDB accession				Example --> EOG09360QC4
- Optional information: -
- Example of lines:						DR   OrthoDB; EOG09360QC4; -.

4.5.26) PDB:
- Resource abbreviation: PDB
- Resource identifier: PDB name 						Example --> 1PSY
- Optional information 1: This field is the structure determination method, which is controlled vocabulary that currently includes: X-ray (for X-ray crystallography), NMR (for NMR spectroscopy), EM (for electron microscopy and cryo-electron diffraction), Fiber (for fiber diffraction), IR (for infrared spectroscopy), Model (for predicted models) and Neutron (for neutron diffraction)
- Optional information 2: This field indicates the resolution of structures that were determined by X-ray crystallography or electron microscopy.
- Example of lines:						DR   PDB; 1PSY; NMR; -; A=33-156.
										DR   PDB; 1PNB; NMR; -; A=1-31, B=32-106.
										DR   PDB; 2DS2; X-ray; 1.70 A; A/C=36-68, B/D=83-154.

4.5.27) Pfam:
- Resource abbreviation: Pfam
- Resource identifier: Pfam accession					Example --> PF00234
- Optional information 1: Entry name 					Example --> Tryp_alpha_amyl
- Optional information 2: Number of hits found in the sequence
- Example of lines:						DR   Pfam; PF00234; Tryp_alpha_amyl; 2.

4.5.28) PIR:
- Resource abbreviation: PIR
- Resource identifier: PIR accession name					Example --> S11499
- Optional information: Entry name							Example --> RZCS
- Example of lines:						DR   PIR; S11499; RZCS.
										DR   PIR; JC5379; JC5379.

4.5.29) PRINTS:
- Resource abbreviation: PRINTS
- Resource identifier: PRINTS accession name					Example --> PR00496
- Optional information: Entry name								Example --> NAPIN
- Example of lines:						DR   PRINTS; PR00496; NAPIN.

4.5.30) Prosite:

Specific format:
DR   PROSITE; ACCESSION_NUMBER; ENTRY_NAME; NUMBER_OF_MATCHES.

- Resource abbreviation: Prosite
- Accession number: Accession number of the PROSITE pattern or profile entry 	Example --> PS00107
- Entry name: Name of the entry													Example --> PROTEIN_KINASE_ATP
- Number of matches:  Number of matches of the pattern or profile in that particular protein sequence
- Example of lines:						DR   PROSITE; PS00107; PROTEIN_KINASE_ATP; 2.

4.5.31) Reactome:
- Resource abbreviation: Reactome
- Resource identifier: Reactome accession						Example --> R-ATH-6798695
- Optional information: Pathway name							Example --> Neutrophil degranulation
- Example of lines:						DR   Reactome; R-ATH-6798695; Neutrophil degranulation.
(Only the number, without the prefix, is added in the previous releases of BIANA. But now, the codes are different and they are not detected with the old regex.
For this reason, I will parse Reactome and see how the codes are parsed, and then decide how I parse the Reactome codes in Uniprot and the other databases.
I have parsed Reactome and it is not correct, all the Reactome codes have value 0. I have to modify the biopaxLevel2Parser.py script and parse Reactome correctly again.
Now, I have corrected the parser, adding only the value of the numeric part of the code and it is correct.
Therefore, here we will do the same and add only the numeric part of the code)

4.5.32) RefSeq
- Resource abbreviation: RefSeq
- Resource identifier: RefSeq accession							Example --> XP_002522855.1
- Optional information: Nucleotide sequence identifier			Example --> XM_002522809.1
- Example of lines:						DR   RefSeq; XP_002522855.1; XM_002522809.1.
										DR   RefSeq; XP_011546040.1; XM_011547738.2.
										DR   RefSeq; XP_017456514.1; XM_017601025.1. [P36877-1]

4.5.33) RGD:
- Resource abbreviation: Reactome
- Resource identifier: RGD accession							Example --> 620920
- Optional information: Gene designation or -					Example --> Ppp2r2c
- Example of lines:						DR   RGD; 620920; Ppp2r2c.

4.5.34) SGD (Saccharomyces Genome Database):
- Resource abbreviation: SGD
- Resource identifier: SGD accession							Example --> S000003910
- Optional information: Gene designation or -					Example --> YJR149W
- Example of lines:						DR   SGD; S000003910; YJR149W.

4.5.35) STRING:
- Resource abbreviation: STRING
- Resource identifier: STRING accession							Example --> 3702.AT5G54740.1
- Optional information: -
- Example of lines:						DR   STRING; 3702.AT5G54740.1; -.
(I will wait until having the STRING parsed, but I think that it will not be necessary, as this code is not introduced in a table
It is processed and introduced in different tables, and for this reason it may be difficult to create a cross-reference, so I would
let it without STRING cross-reference)

4.5.36) Tair (The Arabidopsis Information Resource (TAIR)):
- Resource abbreviation: TAIR
- Resource identifier: Official gene name						Example --> AT5G54740
- Optional information: -										
- Example of lines:						DR   TAIR; AT5G54740; -.

4.5.37) TIGRFAMs (TIGR protein family database (TIGRFAMs)):
- Resource abbreviation: TIGRFAMs
- Resource identifier: TIGRFAMs accession						Example --> TIGR01274
- Optional information 1: Entry name 							Example --> ACC_deam
- Optional information 2: Number of hits found in the sequence	Example --> 1
- Example of lines:						DR   TIGRFAMs; TIGR01274; ACC_deam; 1.
										DR   TIGRFAMs; TIGR00630; uvra; 1.
										DR   TIGRFAMs; TIGR00514; accC; 1.

4.5.38) UniGene:
- Resource abbreviation: UniGene
- Resource identifier: UniGene accession						Example --> At.28623
- Optional information: -
- Example of lines:						DR   UniGene; At.28623; -.
										DR   UniGene; Hs.696211; -.

4.5.39) UniPathway (a resource for the exploration and annotation of metabolic pathways):
- Resource abbreviation: UniPathway
- Resource identifier: UniPathway accession						Example --> UPA00384
- Optional information: Identifier of the reaction 				Example --> UER00562
- Example of lines:						DR   UniPathway; UPA00384; UER00562
										DR   UniPathway; UPA00923; -.

4.5.40) WormBase:
- Resource abbreviation: WormBase
- Resource identifier: Transcript identifier					Example --> M117.2a
- Optional information 1: Protein identifier					Example --> CE06200
- Optional information 2: Gene identifier 						Example --> WBGene00003920
- Optional information 2: Gene designation 						Example --> par-5
- Example of lines:						DR   WormBase; M117.2a; CE06200; WBGene00003920; par-5.
										DR   WormBase; F48E8.5; CE30997; WBGene00003901; paa-1.

4.5.41) WBParaSite (WormBase ParaSite (WBParaSite) resource for parasitic worms (helminths)):
- Resource abbreviation: WBParaSite
- Resource identifier: Transcript identifier					Example --> Bm6838
- Optional information 1: Protein identifier					Example --> Bm6838
- Optional information 2: Gene identifier 						Example --> WBGene00227099
- Optional isoform sequence identifier field
- Example of lines:						DR   WBParaSite; Bm6838; Bm6838; WBGene00227099.
(I think this database is not necessary)

4.5.42) ZFIN (Zebrafish Information Network genome database):
- Resource abbreviation: ZFIN
- Resource identifier: ZFIN accession 							Example --> ZDB-GENE-040426-2086
- Optional information: gene designation or -					Example --> ppp2r2d
- Example of lines:						DR   ZFIN; ZDB-GENE-040426-2086; ppp2r2d.


4.6) Final list of cross-references to be added:

- ChEMBL
(D) DIP
- DisGeNET
- DrugBank
(D) Ensembl
(D) FlyBase
(D) GeneID
(D) GO
(D) HGNC
- HPA
(D) InterPro
(D) KEGG
(D) MGI
(D) MIM
- Orphanet ?
(D) PDB
(D) PIR
(D) PRINTS
(D) Prosite
(D) Reactome
(D) RefSeq
(D) RGD
(D) SGD
- STRING
(D) Tair
(D) TIGRFAMs
(D) UniGene
(D) WormBase

4.7) Things changed

- When adding InterPro cross-references, the whole code is added (i.e. IPR004848). 
  But if we look in other external databases parsed (MINT, IntAct), the codes are added without the IPR- prefix (i.e. 000594)
  I think that I should change this in Uniprot parsing, and add only the number without the prefix.
  Finally, I have do it. I have commented line 80 and added line 81:
        interpro_regex = re.compile("^DR\s+InterPro;\s*IPR(\d+);") # Quim Aguirre: Modification added to cut the prefix IPR-, as it is done in the parsing of other external databases

- When adding RefSeq cross-references, there are some of the entries that have changed and cause errors:
  Some of them contein the nucleotide sequence identifier at the end. For example:
  DR   RefSeq; XP_017456514.1; XM_017601025.1. [P36877-1]
  To avoid problems in the parsing, the regex has been changed.
  I have commented line 96, and added lines 97 and 98, which are the following:
        refseq_regex = re.compile("^DR\s+RefSeq;(.*)\.\s*\[*") # Quim Aguirre: Modification to avoid problems of entries containing nucleotide sequence identifier
                                                               # Example: DR   RefSeq; XP_017456514.1; XM_017601025.1. [P36877-1]

- Reactome: The codes have changed, and now the old regex does not recognise them. I will change the regex, but first I have seen that the database
  was not well parsed. The codes are not recognised as well and it only introduces "0"s in the externalEntityReactome table. I will fix the parser 
  and then I will decide what to do with the cross-references in Uniprot.
  I have already corrected the parser, adding only the numeric part of the code (because the table accepted only integers).
  Therefore, here we will modify the regex to add only the numeric part.
  The lines modified are 105-106:
        reactome_regex = re.compile("^DR\s*Reactome;\s*R-[A-Z]{3}-(\d+);") # Quim Aguirre: Modification to obtain the numeric part of the Reactome code, which has changed respect the previous version
                                                                           # Example of code: R-ECO-159880 --> 159880

- Tair: I will add the cross-reference.
  Line 108:
        tair_regex = re.compile("^DR\s+TAIR;\s*(\S+);") # Quim Aguirre: Addition of TAIR regex
  Lines 567-573:
                # Quim Aguirre: Addition of Tair cross-reference
                m = tair_regex.match(line)
                if m:
            self.verify_attribute_length("tair", m.group(1))
                    uniprotObject.add_attribute(ExternalEntityAttribute(attribute_identifier="Tair", value=m.group(1), type="cross-reference"))

                    continue

- TIGRFAMs: The name of the resource abbreviation has changed. In the previous version, it was TIGR, and now it is "TIGRFAMs".
  For this reason, the regex needs to be changed.
  I have commented line 111, and added line 112:
        tigr_regex = re.compile("^DR\s+TIGRFAMs\;\s+(.+)\;") # Quim Aguirre: Change of the resource abbreviation

- WormBase: Here it happens the same as the case of Reactome. The table externalEntityWormBaseGeneID contains a restriction of only integers.
  It also happens that the information given in this cross-reference is larger, and we only use the GeneIdentifier.
  So, the regex needs to be changed to take the GeneIdentifier and obtain only the numeric part.
  Example of line: DR   WormBase; F48E8.5; CE30997; WBGene00003901; paa-1.
  I have commented line 118 and added line 119:
        WormBase_regex = re.compile("^DR\s+WormBase;\s*.+;\s*.+;\s*WBGene(\d+);\s*(\S+)\.") # Quim Aguirre: Modification to obtain the numeric part of the WormBaseGeneID code


4.8) Upload modifications to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/uniprotParser.py .

And now we can add and commit the changes:

$> git add uniprotParser.py

$> git commit -m "Changes in Uniprot database cross-references"

And push it to the web repository:

$> git push -u origin master




----------------------
5. PARSING OF DISGENET
----------------------

The purpose is to: 
- Download the data of DIsGeNET
- Analyse the data of DisGeNET
- Create a new parser for the database
- Parse the database

5.1) Download the data

We can download the data of DisGeNET from: http://www.disgenet.org/web/DisGeNET/menu/downloads
We will download the following files:
- ALL gene-disease associations: 		all_gene_disease_associations.tsv
- All SNP-gene-disease associations: 	all_snps_sentences_pubmeds.tsv
We will also keep the README file.

5.2) Analyse the data

In the the gene-disease associations file, we have gene disease associations reported by several sources, and with a DisGeNET score given.
Here is an overview of the file:

# This file corresponds to DisGeNET v4.0 (created on Jun 07 2016)
#
# If you have any further questions, please email us at support@disgenet.org
# 
geneId	geneName	description	diseaseId	diseaseName	score	NofPmids	NofSnps	sources
4210	MEFV	Mediterranean fever	umls:C0000727	Abdomen, Acute	0.00290991572276264	2	0	BeFree,GAD
4193	MDM2	MDM2 proto-oncogene, E3 ubiquitin protein ligase	umls:C0000735	Abdominal Neoplasms	0.000271441872080303	1	0	BeFree
2944	GSTM1	glutathione S-transferase mu 1	umls:C0000735	Abdominal Neoplasms	0.000271441872080303	1	0	BeFree
2688	GH1	growth hormone 1	umls:C0000735	Abdominal Neoplasms	0.000271441872080303	1	0	BeFree
387882	C12orf75	chromosome 12 open reading frame 75	umls:C0000735	Abdominal Neoplasms	0.000271441872080303	1	0	BeFree
4982	TNFRSF11B	tumor necrosis factor receptor superfamily, member 11b	umls:C0000735	Abdominal Neoplasms	0.000271441872080303	1	0	BeFree
710	SERPING1	serpin peptidase inhibitor, clade G (C1 inhibitor), member 1	umls:C0000737	Abdominal Pain	0.000542883744160607	2	0	BeFree
10007	GNPDA1	glucosamine-6-phosphate deaminase 1	umls:C0000737	Abdominal Pain	0.000271441872080303	1	0	BeFree
5742	PTGS1	prostaglandin-endoperoxide synthase 1 (prostaglandin G/H synthase and cyclooxygenase)	umls:C0000737	Abdominal Pain	0.00236703197860203	1	0	GAD

Being the columns:
geneId 		-> Entrez Gene Identifier
geneSymbol	-> Official Gene Symbol
geneName 	-> Full Gene Name
diseaseId 	-> UMLS concept unique identifier
diseaseName 	-> Name of the disease	
score		-> DisGENET score for the Gene Disease association
NofPmids	-> total number of papers reporting the Gene Disease association
NofSnps		-> total number of SNPs associated to the Gene Disease association
source		-> Original source reporting the Gene Disease association

In the SNP-gene-disease associations file, there are SNP associations to gene-disease pairs, supported by publications.
Here is an example of the file::

# This file corresponds to DisGeNET v4.0 (created on Jun 14 2016)
#
# If you have any further questions, please email us at support@disgenet.org 
snpId	pubmedId	geneId	geneSymbol	diseaseId	diseaseName	sourceId	sentence	score	year	geneSymbol_dbSNP	CHROMOSOME	POS	REF	ALT
rs1000113	19098858	8792	TNFRSF11A	umls:C0009324	Ulcerative Colitis	BeFree	Allele and genotype frequencies of rs1000113 and rs4958847 were determined in 823 CD (265 younger than 19 years at diagnosis), 353 ulcerative colitis (UC) (130 younger than 19 years at diagnosis), and 578 controls.	0.000271441872080303	2009	IRGM	5	150860514	C	T
rs100012	23206929	1545	CYP1B1	umls:C0339573	Glaucoma, Primary Open Angle	BeFree	Moreover, one haplotype consisting of rs1056827 and rs100012 in CYP1B1 gene was significantly associated with a protective effect against POAG (p = 0.0045; OR = 0.3; 95% CI, 0.1-0.7).	0.365700279313686	2013	NA	NA	NA	NA	NA

Being the columns:
snpId		-> dbSNP Identifier of the variant linked to the Gene Disease association
pubmedId	-> PMID identifier of the paper supporting the association
geneId		-> Entrez Gene Identifier
geneSymbol	-> Official Gene Symbol
diseaseId	-> UMLS concept unique identifier
diseaseName	-> Name of the disease	
sourceId	-> Original source reporting the Gene Disease association
sentence	-> Sentence supporting the association in the publication
score		-> DisGENET score for the Gene Disease association
year		-> Year of publication
geneSymbol_dbSNP-> Gene according to dbSNP database 
CHROMOSOME 	-> Chromosome, according to dbSNP database       
POS  		-> Chromosome Position, according to dbSNP database   
REF 	 	-> Reference Allele, according to dbSNP database   
ALT 		-> Reference Allele, according to dbSNP database  

Here we can find the sources of the associations: http://www.disgenet.org/web/DisGeNET/menu/browser?19
- CTD_human: Comparative Toxicogenomics Database, human data
- UNIPROT: Universal Protein Resource
- CLINVAR: ClinVar, public archive of relationships among sequence variation and human phenotype
- ORPHANET: The portal for rare diseases and orphan drugs
- GWASCAT: The NHGRI-EBI GWAS Catalog
- GAD: Genetic Association Database
- CTD_mouse: Comparative Toxicogenomics Database, Mouse models data
- CTD_rat: Comparative Toxicogenomics Database, Rat models data
- MGD: Mouse Genome Database
- RGD: Rat Genome Database
- LHGDN: Literature-derived human gene-disease network generated by text mining
- BeFree: Text mining data, generated using BeFree System 

Which information should we extract from the database, and which relations should we create?



------------------
6. PARSING OF HPRD
------------------

The purpose is to: 
- Download the data of HPRD
- Analyse the psi-mi25 format
- Analyse the data of HPRD
- Fix the parser
- Parse the database
- Add the modified parser to GitHub
- Modify the manual

The HPRD parser and the IntAct parser were PSI-MI25 parsers that were modified and the modifications were not correct, because the parser was adding external entities to external databases which were not the ones in the externalDatabase table.
Therefore, we will have to analyse the psi-mi25 format, find the error in the parser and fix it.

6.1) Download the data

The data is dowloaded from www.hprd.org

6.2) Analyse the PSI-MI25 format

In the following website, the elements of the PSI-MI25 format (in xml) are explained:

http://www.psidev.info/node/60

6.3) Parse as proof

I will parse HPRD as a proof to see the errors

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5_HPRD --input-identifier=/home/quim/Databases/hprd/PSIMI_XML --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HPRD" --database-version="Release 2010_04 of 13-Apr-2010" --default-attribute="hprd"

It seems that there are no errors. There is only one unique code.

I have done some checking, and I realised that when you parse HPRD with the old parser (psi_mi_2.5) with the empty database, it comes up with the error, deletes everything, but then there are some external entities that are not deleted and remain there:

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/hprd/PSIMI_XML --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HPRD" --database-version="Release 2010_04 of 13-Apr-2010" --default-attribute="hprd"

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
Empty set (0.00 sec)

mysql> select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |      862 |
+--------------------+----------+
1 row in set (0.00 sec)

So, there is an error in the deletion of the external entities of this parser.

6.4) Fix the parser

What I will do is to create the corrected version of the psi_mi_2.5 parser from the scratch, add the changes in GitHub, and parse the database from the scratch. 
IF THERE IS AN ERROR IN A PSI-MI-2.5 DATABASE, WE MUST RESET THE WHOLE BIANA DATABASE BECAUSE IT DOES NOT DELETE THE EXTERNAL ENTITIES CORRECTLY!!!

$> /soft/devel/python-2.7/bin/python reset_biana_database.py -n test_2017 -s localhost -u quim

I changed the parser "psi_Mi25Parser.py" at line 251-2, adding the condition for when experiment.xRefMethodInteraction.refPrimary objects are "NoneType":
            # Some experiment.xRefMethodInteraction.refPrimary objects were "NoneType", and this was giving problems when parsing HPRD, so the second condition has been added by Quim Aguirre
			if experiment.xRefMethodInteraction is not None and experiment.xRefMethodInteraction.refPrimary is not None:

6.5) Parse the database

Now, we can parse HPRD correctly using the modified parser:

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/hprd/PSIMI_XML --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HPRD" --database-version="Release 2010_04 of 13-Apr-2010" --default-attribute="hprd"

Time of parsing:
Total time: 412.444181204 seconds

We will check that the additions have been properly done:

mysql> select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |   206834 |
+--------------------+----------+
1 row in set (0.06 sec)

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
+--------------------+--------------+
| externalDatabaseID | DatabaseName |
+--------------------+--------------+
|                  1 | hprd         |
+--------------------+--------------+
1 row in set (0.00 sec)

Yes, there is only one type of externalDatabaseID, and only one database parsed.

6.6) Add the modified parser to GitHub

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master
From https://github.com/emreg00/biana
 * branch            master     -> FETCH_HEAD
Already up-to-date.

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/psi_Mi25Parser.py .

We can check the status after copying the modified file by using "status" command:
$> git status
# On branch master
# Changed but not updated:
#   (use "git add <file>..." to update what will be committed)
#   (use "git checkout -- <file>..." to discard changes in working directory)
#
#	modified:   psi_Mi25Parser.py
#
no changes added to commit (use "git add" and/or "git commit -a")

Here we can see how git indicates that the parser has been modified but not updated. So, let's update it:
First, we add the changes:

$> git add psi_Mi25Parser.py

Now if we check the status, we can see that we have added the parser but needs to be commited:

$> git status
# On branch master
# Changes to be committed:
#   (use "git reset HEAD <file>..." to unstage)
#
#	modified:   psi_Mi25Parser.py
#

So, let's commit:

$> git commit -m "Change in psi_mi25 to solve an error when parsing HPRD"
[master a254c2c] Change in psi_mi25 to solve an error when parsing HPRD
 Committer: quim <quim@rabin.prib.upf.edu>
Your name and email address were configured automatically based
on your username and hostname. Please check that they are accurate.
You can suppress this message by setting them explicitly:

    git config --global user.name "Your Name"
    git config --global user.email you@example.com

If the identity used for this commit is wrong, you can fix it with:

    git commit --amend --author='Your Name <you@example.com>'

 1 files changed, 2 insertions(+), 1 deletions(-)

We can see the history of commits using "log" command:

$> git log

And now, we can use the "push" command to tell Git to push our local changes to our repository on GitHub
The name of our remote is origin and the default local branch name is master. The -u tells Git to remember the parameters, so that next time we can simply run git push and Git will know what to do. Let's push!!

$> git push -u origin master



--------------------
7. PARSING OF INTACT
--------------------

The purpose is to: 
- Download the data of IntAct
- Analyse the parsing errors of IntAct
- Correct the psi-mi25 parser
- Parse the database
- Add the modified parser to GitHub
- Modify the manual


7.1) Download the data

The data can be seen in the website: ftp://ftp.ebi.ac.uk/pub/databases/intact/current/psi25/species/
It is dowloaded using the script "ftp_intact":

$> cd /home/quim/Databases
$> mkdir intact
$> cd intact/
$> sh ../ftp_get_database.sh ../ftp_intact


7.2) Analyse the parsing errors of IntAct

The changes in the data of IntAct cause errors when parsing using the original psi_mi25 parser. Let's remember these errors.
First, we will reset the database:

$> cd ../..
$> /soft/devel/python-2.7/bin/python reset_biana_database.py -n test_2017 -s localhost -u quim

And now, we will parse the database using the psi_mi25 parser:

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/intact/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="IntAct" --database-version="Release 2016_10 of 06-Oct-2016" --default-attribute="intact"

The following error was found:

Traceback (most recent call last):
  File "/home/quim/BIANA/biana/BianaParser/bianaParser.py", line 196, in start
    self.parse_database()
  File "/home/quim/BIANA/biana/BianaParser/psi_Mi25Parser.py", line 197, in parse_database
    psi_MiFormatted_object = ExternalEntity( source_database = self.database, type=interactorType) # "protein")
  File "/home/quim/BIANA/biana/BianaObjects/ExternalEntity.py", line 45, in __init__
    type = type.lower()
AttributeError: 'NoneType' object has no attribute 'lower'
ERROR WHILE PARSING. ALL MODIFICATIONS ARE GOING TO BE DELETED

It is an error related with the fact that the "interactorType" variable is None, and it gives error subsequently.

Then, when we check if the modifications have been deleted correctly, we come up with the same problem of HPRD, they are not correctly removed:

mysql> select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |    24946 |
+--------------------+----------+
1 row in set (0.02 sec)

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
Empty set (0.00 sec)

In this case we will do the same as HPRD. We will reset the database if there is an error related with the psi-mi25 parser. And we will fix the parser and parse again the database.


7.3) Correct the psi-mi25 parser

What we will do is to skip the cases in which "interactorType" object is None.
To do so, I have added these three lines in line 197:

                        # Quim Aguirre: Condition added for skipping the cases in which objInteractor.type.name is also None in IntAct database
                        if interactorType is None:
                            continue

7.4) Parse the database

Now, we will reset the database:

$> /soft/devel/python-2.7/bin/python reset_biana_database.py -n test_2017 -s localhost -u quim

And we will parse again the database using the modified parser:

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/intact/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="IntAct" --database-version="Release 2016_10 of 06-Oct-2016" --default-attribute="intact"

Parsing time: 6289.66252494 seconds

The parsing has been correct. We will check it in mysql database:

mysql> select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |  1263816 |
+--------------------+----------+
1 row in set (0.36 sec)

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
+--------------------+--------------+
| externalDatabaseID | DatabaseName |
+--------------------+--------------+
|                  1 | intact       |
+--------------------+--------------+
1 row in set (0.00 sec)

Yes, there is only one externalDatabaseID corresponding to IntAct.

7.4.2) Addition

I have realised that IntAct was parsing gene names/descriptions of aliases in the GeneSymbol table.
In order to avoid this, I have stated that only the ones of type "gene name" could be classified as GeneSymbol.
The ones classified as type "gene name synonym" are ignored

The change in the code is from line 458 to 465:

        if type == "gene name":
            # Example of gene name: EEF1A2
            attributeName = "GeneSymbol"
            #nameType = "alias"
        elif type == "gene name synonym":
            # Example of gene name synonym: Eukaryotic elongation factor 1 A-2
            attributeName = "ignore" # If it is gene name synonym, we will ignore because we have enough information in the database
            #nameType = "cross-reference"

New parsing time: 8202.41169906 seconds = 136 minutes = 2 hours 15 minutes


7.5) Add the modified parser to GitHub

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/psi_Mi25Parser.py .

And now we can add and commit the changes:

$> git add psi_Mi25Parser.py

$> git commit -m "Change in psi_mi25 to solve an error when parsing IntAct"

And push it to the web repository:

$> git push -u origin master 



---------------------
8. PARSING OF BIOGRID
---------------------

The purpose is to: 
- Download the data of BioGRID
- Parse the database


8.1) Dowload the data of BioGRID

The data is dowloaded from the website: https://thebiogrid.org/download.php

The files dowloaded are: BIOGRID-ORGANISM-x.x.xx.psi25.zip --> This file needs to be unzipped

The files are uncompressed in a BIOGRID-ORGANISM-x.x.xx folder. The path of this folder will be the input identifier.

Version: 3.4.143 (25th of November of 2016)

8.2) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/biogrid/BIOGRID-ORGANISM-3.4.143.psi25/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="BioGrid" --database-version="Release 3.4.143 (25-Nov-2016)" --default-attribute="biogrid"

I stopped the parsing because I did not wanted to wait now, I checked the number of externalDatabaseIDs, and we can see that when you stop a parsing with the psi_mi_2.5 parser, it does not delete well the records!!

select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |  1263816 |
|                  2 |    41607 |
+--------------------+----------+
2 rows in set (0.42 sec)

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
+--------------------+--------------+
| externalDatabaseID | DatabaseName |
+--------------------+--------------+
|                  1 | intact       |
+--------------------+--------------+
1 row in set (0.00 sec)

I will parse BioGRID when I do the definitive database.

Parsing time: 3101.04378104 seconds



-----------------
9. PARSING OF DIP
-----------------

The purpose is to: 
- Download the data of DIP
- Parse the database
- Modify the manual


9.1) Dowload the data of DIP

The data is dowloaded from the website: http://dip.doe-mbi.ucla.edu/dip/Download.cgi

You need to register:

- User name:  joaquim.aguirre
- Password:  FWZ2s

The files dowloaded are: FULL file from downloads, which is complete DIP dataset (file dipxxxxxxxx.mif25.gz)

The input identifier will be the path to the file: dipxxxxxxxx.mif25

Version: Release 2016_07 of 31-Jul-2016


9.2) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/dip/dip20160731.mif25 --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DIP" --database-version="Release 2016_07 of 31-Jul-2016" --default-attribute="dip"

Parsing time: 152.851712942 seconds
MODIFY MANUAL!!



------------------------------------------
10. PARSING OF MIPS MAMMALIAN PPI DATABASE
------------------------------------------

The purpose is to:
- Download the data of MIPS
- Parse the database
- Modify the manual


10.1) Dowload the data of DIP

The initial idea was to dowload MIPS-MPACT, which was a database of PPI from yeast.
Now, this database does not exist, but instead, MIPS has a database of Mammalian PPIs.
The data is dowloaded from the website: http://mips.helmholtz-muenchen.de/proj/ppi/

The file downloaded is: mppi.gz --> uncompressed: allppis.xml

The input identifier will be the path to the file: allppis.xml

Version: November 2004
Reference: Bioinformatics 2005; 21(6):832-834; [Epub 2004 Nov 5]


10.2) Parse the database

$> -



-------------------
11. PARSING OF MINT
-------------------

The purpose is to: 

- Modify the manual


http://mint.bio.uniroma2.it/index.py

MINT is not currently available. It is now integrated inside the infrastructure of IntAct.

We have modified the manual introducing a note which tells the incidence.



-----------------------
12. PARSING OF REACTOME
-----------------------

The purpose is to: 

- Download the data of Reactome
- Parse the database
- Modify the manual


12.1) Download the data of Reactome

The data is downloaded from this website: http://www.reactome.org/pages/download-data/

The files dowloaded are: ``Events in the BioPAX Level 2 format'' file. Uncompress this file

The input identifier will be: Path where uncompressed files are

Version: v58 (October 5, 2016)


12.2) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py biopax_level_2 --input-identifier=/home/quim/Databases/reactome/biopax2/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Reactome" --database-version="v58 (05-Oct-2016)" --default-attribute="reactome"

Parsing time: 1269.17087603 seconds

The database has been well parsed:

mysql> select externalDatabaseID, count(*) from externalEntity group by externalDatabaseID;
+--------------------+----------+
| externalDatabaseID | count(*) |
+--------------------+----------+
|                  1 |   110391 |
|                  2 |   290633 |
+--------------------+----------+
2 rows in set (0.12 sec)

mysql> select externalDatabaseID, DatabaseName from externalDatabase;
+--------------------+--------------+
| externalDatabaseID | DatabaseName |
+--------------------+--------------+
|                  1 | dip          |
|                  2 | reactome     |
+--------------------+--------------+
2 rows in set (0.00 sec)


12.3) Errors

Everything seems to be correct except one thing:

When parsing the codes of Reactome, they have changed and now they have the following shape: "R-ECO-159880"
In the previous versions, there was only the number (e.g. 159880). For this reason, the table the restriction that the 
records introduced in the column "value" must be integers of maximum 10 characters:

mysql> describe externalEntityReactome;
+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+------+-----+---------+-------+
| Field            | Type                                                                                                                                          | Null | Key | Default | Extra |
+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+------+-----+---------+-------+
| value            | int(10) unsigned                                                                                                                              | NO   | MUL | NULL    |       |
| externalEntityID | int(4) unsigned                                                                                                                               | NO   | MUL | NULL    |       |
| type             | enum('alias','broad_synonym','cross-reference','exact_synonym','narrow_synonym','previous','related_synonym','short-name','synonym','unique') | YES  |     | NULL    |       |
+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+------+-----+---------+-------+

For this reason, we will only introduce the number of the Reactome code.
To do so, we will introduce the following lines (218-221) in the parser script "biopaxLevel2Parser.py":

                        # Quim Aguirre: I have introduced this condition in order to split the Reactome code and only introduce the number of the code
                        # Example: R-ECO-159880 --> 159880
                        if BiopaxEntity.datatype_to_biana_type[xref_object.db.lower()].lower() == 'reactome':
                            value = value.split("-")[2]

After this, the parsing was correct.


12.4) Add to Github the modificated parser

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/biopaxLevel2Parser.py .

And now we can add and commit the changes:

$> git add biopaxLevel2Parser.py

$> git commit -m "Change to process Reactome codes before adding them to the database"

And push it to the web repository:

$> git push -u origin master



-----------------
13. PARSING OF GO
-----------------

The purpose is to: 

- Download the data of GO
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add to Github


13.1) Download the data of GO

The data is downloaded from this website: http://www.geneontology.org/ontology/gene_ontology_edit.obo

The files dowloaded are: gene_ontology_edit.obo

The input identifier will be: Path to gene_ontology_edit.obo

Version: 1.2 (December 8, 2016)


13.2) Analyse the data and parser

The data has the following shape:

[Term]
id: GO:0000018
name: regulation of DNA recombination
namespace: biological_process
def: "Any process that modulates the frequency, rate or extent of DNA recombination, a DNA metabolic process in which a new genotype is formed by reassortment of genes resulting in gene combinations different from those that were present in the parents." [GOC:go_curators, ISBN:0198506732]
subset: gosubset_prok
is_a: GO:0051052 ! regulation of DNA metabolic process
relationship: regulates GO:0006310 ! DNA recombination

It introduces terms ([Term]), and each term has different tags. 
There are two mandatory tags: id and name
There are lots of optional tags: namespace, def, synonym, subset, is_a, relationship, xref...

Here we have information of the format: http://owlcollab.github.io/oboformat/doc/GO.format.obo-1_2.html

The parser only keeps record of the following tags:
- id
- name
- namespace: type of GO (biological_process/cellular_component/molecular_function/universal)
- def: The definition of the current term
- synonym (exact or related) --> Now there are: EXACT, BROAD, NARROW, RELATED
- is_a: This tag describes a subclassing relationship between one term and another
- relationship

It may be missing some tags:
- subset: This tag indicates a term subset to which this term belongs
- comment: A comment for this term
- xref: A dbxref that describes an analagous term in another vocabulary
- alt_id: Defines an alternate id for this term. A term may have any number of alternate ids

Consult with Emre the importance of adding or not some terms... In principle, I think that they are not important

Let's see how many types of namespace there are:

mysql> select DISTINCT(value) from externalEntityGO_type;
+--------------------+
| value              |
+--------------------+
|                    |
| molecular_function |
| cellular_component |
| biological_process |
+--------------------+
4 rows in set (0.02 sec)

There is one empty, which must be avoided!!

mysql> select * from externalEntityGO_type as T join externalEntityGO as G on T.externalEntityID = G.externalEntityID where T.value = "";
+-------+------------------+--------+---------+------------------+--------+
| value | externalEntityID | type   | value   | externalEntityID | type   |
+-------+------------------+--------+---------+------------------+--------+
|       |            45934 | unique | 2001317 |            45934 | unique |
+-------+------------------+--------+---------+------------------+--------+
1 row in set (0.00 sec)

I have found the error. The fact is that this is the last record. And it does not recognise the end, so it accidentally records the namespace of a [Typedef] entry, which is wrong.

I have fixed this by introducing the term "typedef", so that when it recognises a tag [Typedef] the string typedef is True, and it skips the recording.
And when it identifies another term, it gets False.

We may have to add as well the BROAD and NARROW synonyms:

I have added them. To do so, I had to change the file "BIANA/biana/biana_globals.py".
I had to add the terms "broad_synonym" and "narrow_synonym" at the list of line 142:

VALID_IDENTIFIER_REFERENCE_TYPES = ["unique", "previous", "alias", "cross-reference", "synonym","short-name", "exact_synonym", "related_synonym", "broad_synonym", "narrow_synonym"]

And I have introduced the recording of broad and narrow synonyms at the parser gooboParser.py

The files "biana_globals.py" and "gooboParser.py" need to be uploaded at GitHub.

I will also add the alt_id terms as "alias" in the database:

I have added the recording of alt_id tags in a list "term_alt_id". They are inserted as "alias" in the externalEntityGO table.


13.3) Modify the parser

Go to the parser to see the modifications, but in summary, they are:

- Recognise the term [Typedef], so that it skips the recording when entering to this type of tag
- Add the types of synonyms "broad_synonym" and "narrow_synonym". This included a change in the file "biana_globals.py"
- Recognise and add the tags "alt_id" as "alias" in the externalEntityGO table


13.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py go_obo --input-identifier=/home/quim/Databases/go/gene_ontology_edit.obo --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="GO" --database-version="VERSION 1.2 (December 8, 2016)"

PARSE!!

Total time: 60.4946711063 seconds = 1 minute


13.5) Add to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/gooboParser.py .

And now we can add and commit the changes:

$> git add gooboParser.py

$> git commit -m "Change to skip typedef terms, add broad and narrow synonyms and add alt_id tags"

And push it to the web repository:

$> git push -u origin master 

Add the "biana_globals.py" file to Github:

$> cd /home/quim/biana_git/biana
$> cp /home/quim/BIANA/biana/biana_globals.py .
$> git add biana_globals.py
$> git commit -m "Addition of broad_synonym and narrow_synonym in VALID_IDENTIFIER_REFERENCE_TYPES list"
$> git push -u origin master 



-------------------------
14. PARSING OF PSI-MI-OBO
-------------------------

The purpose is to: 

- Download the data of GO
- Analyse the data and parser
- Parse the database
- Modify the manual

14.1) Download the data of GO

Download the data from: http://www.psidev.info/node/60

File needed: psi-mi.obo

Input identifier: psi-mi.obo

Version: 1.2 (October 22, 2014)


14.2) Analyse the data and parser

The idea is the same as in Gene Onthology: It is a list of terms, and each term has tags.
The parser only keeps record of the following tags:
- id
- name
- def
- synonym (exact or related)
- is_a
- relationship


14.3) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_obo --input-identifier=/home/quim/Databases/psi_mi_obo/psi-mi.obo --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="PSI-MI Obo" --database-version="VERSION 1.2 (October 22, 2014)"

Parsing time: 1.01427197456 seconds

We can see that there are only "psimioboontologyelements" external entity types.

mysql> select type, count(*) from externalEntity order by externalEntityID limit 50;
+-------------------------+----------+
| type                    | count(*) |
+-------------------------+----------+
| psimioboontologyelement |     1375 |
+-------------------------+----------+

It populates 1374 entries in the tables: externalEntitypsimi_name, externalEntityMethod_id, externalEntityDescription

It is well parsed. I think that it is not necessary to add the new terms, as there is enough information, we do not need more.

MODIFY MANUAL!!	



-----------------------
15. PARSING OF TAXONOMY
-----------------------

The purpose is to: 

- Download the data of Taxonomy
- Analyse the data and parser
- Parse the database
- Modify the manual

15.1) Download the data of Taxonomy

Website: ftp://ftp.ncbi.nih.gov/pub/taxonomy/

File needed: taxdump.tar.Z --> uncompress

Input identifier: taxdump

Version: Release 2016_12 of 12-Dec-2016

15.2) Analyse the data and parser

First, it reads the names file and gets:
- The tax id
- The tax name
- Comment
Then, it reads the nodes file and gets:
- Tax id
- Parent tax id

I think that it is perfectly parsed

15.3) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py taxonomy --input-identifier=/home/quim/Databases/taxonomy/taxdump/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Taxonomy" --database-version="Release 2016_12 of 12-Dec-2016"

Parsing time: 1124.43604398 seconds = 20 minutes

I have checked it and it seems to be well parsed. At least, you can find human:

mysql> select * from externalEntityTaxID_name where value="human" order by externalEntityID limit 50;
+-------+------------------+--------+---------------------+
| value | externalEntityID | type   | taxid_name_type     |
+-------+------------------+--------+---------------------+
| human |             7778 | unique | genbank common name |
+-------+------------------+--------+---------------------+

mysql> select * from externalEntityTaxID where externalEntityID=7778 order by externalEntityID limit 50;
+-------+------------------+--------+
| value | externalEntityID | type   |
+-------+------------------+--------+
|  9606 |             7778 | unique |
+-------+------------------+--------+



------------------
16. PARSING OF IPI
------------------

The purpose is to: 

- Download the data of IPI
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add the modified parser to Github

16.1) Download the data of IPI

NOTE: IPI has now closed. The last release is archived at ftp://ftp.ebi.ac.uk/pub/databases/IPI

Website: ftp://ftp.ebi.ac.uk/pub/databases/IPI/last_release/current/

Download: All the files in the ftp site

> cd ipi
> sh ../ftp_get_database.sh ../ftp_ipi &

Version: Release 2011_09 of 27-Sep-2011


16.2) Analyse the data and parser

Example of data:

>IPI:IPI00000477.4|TREMBL:E7EWG5;Q9BXV5 Tax_Id=9606 Gene_Symbol=ARPC2 Uncharacterized protein
MVSISLKFYKELQAHGADELLKRVYGSFLVNPESGYNVSLLYDLENLPASKDSIVHQAGM
LKRNCFASVFEKYFQFQEEGKEGENRAVIHYRDDETMYVESKKDRVTVVFSTVFKDDDDV
VIGKVFMQEFKEGRRASHTAPQVLFSHREPPLELKDTDAAVGDNIGYITFGAVPSSHQCQ
CSRQHHQPDPHVPGLPALPH

The parser obtains the identifiers and stores them into BIANA.
I think that it is fine, but there is an error when parsing the Gene Symbol.
It does not use the result obtained from the regex. 
Then, it should also separate the result when there are multiple results.
And finally, it should skip the "-" gene symbol entries.


16.3) Modify the parser

From line 175 to 182:

                # Quim Aguirre: Change to add the gene symbol using the regex, add multiple entries when necessary, and skip when '-'
                search = gene_symbol_regex.search(line)
                gene_symbols = search.group(1).split(';')
                for gene_symbol in gene_symbols:
                    if search and gene_symbol != '-':
                        ipi_object.add_attribute(ExternalEntityAttribute(attribute_identifier="geneSymbol",
                                                                         value = gene_symbol,
                                                                         type = "cross-reference" ))


16.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py ipi --input-identifier=/home/quim/Databases/ipi/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="ipi" --database-version="Release 2011_09 of 27-Sep-2011"

Parsing time: 805.067059994 seconds = 10 minutes


16.5) Add the modified parser to GitHub

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/ipiParser.py .

And now we can add and commit the changes:

$> git add ipiParser.py

$> git commit -m "Change in IPI to add correctly gene symbols, add them multiple times and skip empty entries"

And push it to the web repository:

$> git push -u origin master


-----------------------
17. PARSING OF COG 2014
-----------------------

The purpose is to: 

- Download the data of COG 2014
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add the modified parser to Github


17.1) Download the data of COG 2014

Website: ftp://ftp.ncbi.nih.gov/pub/COG/COG2014/data/

Download files: prot2003-2014.fa, prot2003-2014.tab, genomes2003-2014.tab, fun2003-2014.tab, cognames2003-2014.tab, cog2003-2014.csv, prot2003-2014.gi2gbk.tab

$> cd /home/quim/Databases/cog2014_2016/
$> sh ../ftp_get_database.sh ../ftp_cog2014 &
Unzip the file prot2003-2014.fa.gz

Input identifier: path to folder containing files

Version: 2014, with some modifications of 2016


17.2) Analyse the data and parser

The data has got a new file: "prot2003-2014.gi2gbk.tab". This file contains RefSeq and GenBank accession codes for all proteins with assigned COG domains.

Why this file is being updated now?  The README says this:

"Sequences in COGs are identified by GenBank GI numbers. GI numbers
generally are transient. There are two ways to make a more permanent
link between the protein in COGs and the outside databases: via the
RefSeq accession codes (see 2.5) and via the protein sequences (see
2.6).
Note, however, that at the moment (April 02, 2015) RefSeq database is
in a state of transition; some of the <refseq-acc> entries are not
accessible. This accession table will be updated as soon as RefSeq is
stable."

Now, at 2016, the RefSeq database is more stable and the file has been updated with RefSeqs.
However, not all the COGs have their RefSeq. The README states this:

"As of now (October 13, 2016) 5391 out of 1785722 proteins miss
GenBank accession codes. We will upload the updated table as soon as
possible."

So, we have to be aware for changes soon.

But by now, we can update the parser and introduce the new file "prot2003-2014.gi2gbk.tab".

In this file, there is the same number of COGs than in "prot2003-2014.tab", so we will only work with prot2003-2014.gi2gbk.tab, because it contains more information.

I have made a script to analyse the content of this file, the script is called "analyse_cog.py" and is placed in scripts of BIANA.
With the script, I have seen that the file has always three fields (protein_name (genbank GI), refseq, genbank accession).

The first thing that we will change is that we will classify the protein_name as GI (before, it was OrderedLocusName, but in this version this has changed).
Then, we have a new cross-reference, which is the genbank accession. I will add it as AccessionNumber


17.3) Modify the parser

- I have changed line 93-103 for:

        name_to_refseq_dict = {}
        name_to_gb_dict = {}
        name2refseqgb_file_fd = open(self.input_path+os.sep+"prot2003-2014.gi2gbk.tab",'r')

        for line in name2refseqgb_file_fd:
            (protein_name, refseq, genbank) = line.strip().split("\t")
            ## Example --> 103485499	YP_615060	ABF51727
            name_to_refseq_dict[refseq.lower()] = protein_name
            name_to_gb_dict[genbank.lower()] = protein_name

        name2refseqgb_file_fd.close()

- I have added lines 172-182:
            if name2refseq_dict.has_key(protein_name.lower()):
                # Add an attribute to the External Entity --> the RefSeq identifier
                eE_object.add_attribute(ExternalEntityAttribute( attribute_identifier = "RefSeq", 
                                                                 value = name2refseq_dict[protein_name.lower()],
								 type="cross-reference" ))

            if name_to_gb_dict.has_key(protein_name.lower()):
                # Add an attribute to the External Entity --> the GeneBank accession
                eE_object.add_attribute(ExternalEntityAttribute( attribute_identifier = "AccessionNumber", 
                                                                 value = name_to_gb_dict[protein_name.lower()],
								 type="cross-reference" ))

- I have changed lines 209-212:
                    # Add an attribute to the External Entity --> the protein name, in this case is classified as GenBank GI
                    eE_object.add_attribute( ExternalEntityAttribute( attribute_identifier = "GI",
                                                                      value = protein_name,
								      type="cross-reference" ) )

- And I have commented better the code


17.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py cog --input-identifier=/home/quim/Databases/cog2014/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="COG" --database-version="2014 update" --promiscuous

Total time: 1619.29103613 seconds = 27 minutes


17.5) Add the modified parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/cogParser_2014.py .

And now we can add and commit the changes:

$> git add cogParser_2014.py

$> git commit -m "New parser of COG version 2014, adapted from the old parser"

And push it to the web repository:

$> git push -u origin master


17.6) Make the last version to be "cogParser.py"

I will change the file and the name, so that the last version, now called cogParser_2014.py, is recalled as cogParser.py.

First, I will change the parser.

- Line 27:     name = "cog"
- Line 37:                             default_script_name = "cogParser.py",

Now, I will update github:

$> git pull emre master

I will copy the changed file to the github local folder:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/cogParser_2014.py .

Now, I will use the command git mv to change the name of the parser:
First, I need to change the name of the cog old parser to 2003

$> git mv cogParser.py cogParser_2003.py
$> git mv cogParser_2014.py cogParser.py

$> git add cogParser.py

$> git commit -m "Old version (2003) renamed to cogParser_2003.py. New version (2014) renamed to cogParser.py"

$> git push -u origin master

Now I will change the old parser (if not, the new one cannot work because the name of the parser is the same) and add it to github:

- Line 27:    name = "cog_2003"
- Line 37:                             default_script_name = "cogParser_2003.py",

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/cogParser_2003.py .
$> git add cogParser_2003.py
$> git commit -m "Modification in the name of the old cogParser, so that the new one can work properly"
$> git push -u origin master

Add modifications to COG parser:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/cogParser.py .
$> git add cogParser.py
$> git commit -m "Change in name of the dict 'name_to_gb_dict' to 'name2gb_dict'"
$> git push -u origin master


-------------------
18. PARSING OF HGNC
-------------------

The purpose is to: 

- Download the data of HGNC
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add the modified parser to Github


18.1) Download the data of HGNC

Website: http://www.genenames.org/cgi-bin/statistics

Download: hgnc_complete_set.txt

Input identifier: the file

Version: Release 2016_12 of 13-Dec-2016


18.2) Analyse the data and parser

The names of the columns have changed a lot respect with the previous version.
For this reason, a new parser called "hgncParser_2016.py" has been done.
What I have done is to analyse every column in the database, and decide if I include it in the database, and in which table I include it.
I finally have included the following columns:

# column name 			# biana type of attribute
- symbol 				geneSymbol
- name 					description
- alias_symbol 			geneSymbol
- alias_name 			description
- prev_symbol 			geneSymbol
- prev_name 			description
- entrez_id 			geneID
- ensembl_gene_id 		Ensembl
- ena 					AccessionNumber
- refseq_accession 		RefSeq
- uniprot_ids 			UniprotAccession
- pubmed_id 			Pubmed
- mgd_id 				MGI
- rgd_id 				RGD
- omim_id 				MIM
- imgt 					IMGT
- enzyme_id 			eC

The cases in which there were more than two items for one column, they were separated using "|".
In the code, we have split these cases and added them all


18.3) Modify the parser

The parser has been fully modified, although the structure is the same as the old parser.
Have a look to the parser to see how it works.


18.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py hgnc_2016 --input-identifier=/home/quim/Databases/hgnc/hgnc_complete_set.txt --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HGNC" --database-version="Release 2016_12 of 13-Dec-2016"

Total time: 31.3423500061 seconds


18.5) Add the modified parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/hgncParser_2016.py .

And now we can add and commit the changes:

$> git add hgncParser_2016.py

$> git commit -m "New parser of HGNC for the current status of the database (2016), adapted from the old parser"

And push it to the web repository:

$> git push -u origin master


18.6) Make the last version to be "hgncParser.py"

I will change the file and the name, so that the last version, now called hgncParser_2016.py, is recalled as hgncParser.py.

First, I will change the parser.

- Line 44:    name = "hgnc"
- Line 54:                             default_script_name = "hgncParser.py",

Now, I will update github:

$> git pull emre master

I will copy the changed file to the github local folder:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/hgncParser_2016.py .

Now, I will use the command git mv to change the name of the parser:
First, I need to change the name of the cog old parser to 

$> git mv hgncParser.py hgncParser_old.py
$> git mv hgncParser_2016.py hgncParser.py

$> git add hgncParser.py

$> git commit -m "Old version (2007) renamed to hgncParser_old.py. New version (2016) renamed to hgncParser.py"

$> git push -u origin master

Now I will change the old parser (if not, the new one cannot work because the name of the parser is the same) and add it to github:

- Line 41:    name = "hgnc_old"
- Line 51:                             default_script_name = "hgncParser_old.py",

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/hgncParser_old.py .
$> git add hgncParser_old.py
$> git commit -m "Modification in the name of the old hgncParser, so that the new one can work properly"
$> git push -u origin master



------------------------
19. PARSING OF IREFINDEX
------------------------

The purpose is to: 

- Download the data of iRefIndex
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add the modified parser to Github


19.1) Download the data of iRefIndex

Website: http://irefindex.org/download/irefindex/data/archive/release_14.0/psi_mitab/MITAB2.6/

Download: File All.mitab.??????.txt.zip

Input identifier: the file

Version: 14.0 (last edited in 2016-07-23)


19.2) Analyse the data and parser

The information of the current database can be found in: http://irefindex.org/wiki/index.php?title=README_MITAB2.6_for_iRefIndex

There are three types of interactions, located at column 53 (edgetype):

- Binary interaction: Marked as "X". Interactors A and B will list the two proteins for which interaction evidence is provided in the row
- Complexes (n-ary data): Marked as "C".  let’s say that a source interaction record contained interactors A, B and C found by affinity purification and mass-spec where a tagged version of protein A was used as the bait protein to perform the immunoprecipitation. 
  We would represent the complex with three lines: X-A, X-B and X-C
- Intramolecular interactions and multimers: Marked as "Y". Interaction records which only list one interactor.


PubMed Identifiers (PMIDs) point to literature references that support an interaction. A PMID may be used to support more than one interaction. 
Each reference is presented as a scoreName:score pair. Three confidence scores are provided: lpr, hpr and np
- The lpr score (lowest PMID re-use) is the lowest number of distinct interactions that any one PMID (supporting the interaction in this row) is used to support. A value of one indicates that at least one of the PMIDs supporting this interaction has never been used to support any other interaction.
- The hpr score (highest PMID re-use) is the highest number of interactions that any one PMID (supporting the interaction in this row) is used to support. A high value (e.g. greater than 50) indicates that one PMID describes at least 50 other interactions and it is more likely that high-throughput methods were used
- The np score (number PMIDs) is the total number of unique PMIDs used to support the interaction described in this row. 

Each interactor is identified by a ROGID, which is placed in columns 33/34 (Checksum_A/Checksum_B).
Example: rogid:hhZYhMtr5JC1lGIKtR1wxHAd3JY83333

Then, the interaction is identified by a RIGID, which is indicated in column 35 (Checksum_Interaction):

The RIGID consists of the ROG identifiers for each of the protein participants ordered by ASCII-based lexicographic sorting in ascending order, concatenated and then digested with the SHA-1 algorithm.
Example: 	rigid:3ERiFkUFsm7ZUHIRJTx8ZlHILRA


19.3) Modify the parser

The parser has been fully modified in order to satisfy the changes of the current version. However, the structure is based on the old parser.
Look at the parser to see the changes and how it works.


19.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py irefindex --input-identifier=/home/quim/Databases/irefindex/All.mitab.04072015.txt --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="iRefIndex" --database-version="14.0 (last edited in 2016-07-23)"

Parsing time: 747.326686144 seconds = 12 minutes


19.5) Add the modified parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/iRefIndexParser_2016.py .

And now we can add and commit the changes:

$> git add iRefIndexParser_2016.py

$> git commit -m "New parser of iRefIndex for the current status of the database (2016), adapted from the old parser"

And push it to the web repository:

$> git push -u origin master


19.6) Change the last version of the parser name to iRefIndexParser.py

I will modify the new parser:

- Line 29:    name = "iRefIndex"
- Line 40:                              default_script_name = "iRefIndexParser.py",

I will change the name of the old version of the parser to iRefIndexParser_old.py:

$> git mv iRefIndexParser.py iRefIndexParser_old.py

And I will copy the new version and change the name of the new version to iRefIndexParser.py:

$> cp /home/quim/BIANA/biana/BianaParser/iRefIndexParser_2016.py

$> git mv iRefIndexParser_2016.py iRefIndexParser.py

And I will add and commit the changes:

$> git add iRefIndexParser.py

$> git commit -m "Old version (2009) renamed to iRefIndexParser_old.py. New version (2016) renamed to iRefIndexParser.py"

$> git push -u origin master

Now I will change the old parser (if not, the new one cannot work because the name of the parser is the same) and add it to github:

- Line 28:    name = "iRefIndex_old"
- Line 39:                              default_script_name = "iRefIndexParser_old.py",

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/iRefIndexParser_old.py .
$> git add iRefIndexParser_old.py
$> git commit -m "Modification in the name of the old iRefIndexParser, so that the new one can work properly"
$> git push -u origin master


-------------------
20. PARSING OF SCOP
-------------------

The purpose is to: 

- Download the data of SCOP
- Analyse the data and parser
- Modify the parser
- Parse the database
- Add the modified parser to Github

20.1) Download the data of SCOP

Website: http://scop.berkeley.edu/downloads/

Download: All parsable SCOPe files

Input identifier: Path were files are found

Version: 2.06


20.2) Analyse the data and parser

First of all, I should change the system of recognition of the input files.
I have changed it.

Then, I investigated how the parser works.
It parses two of the files:

- dir.cla.scope.txt
- dir.des.scope.txt

For the first one, it takes the PDBs and their corresponding "sunid" code (a SCOP ID) for each of the classification categories.
( Classification categories: cl - class; cf - fold; sf - superfamily; fa - family; dm - protein; sp - species; px - domain )

For the second one, it takes the "sunid", its classification, and its description.

The data is introduced in the following tables:

- externalEntitySCOP --> "sunid"
- externalEntitySCOP_Category --> "category"
- externalEntityPDB --> "pdb" + "chain" + "pdb_range"
- externalEntityDescription --> "description" of the sunid
- externalEntityTaxID --> "taxid"

There is also a hierarchy of categories. This is used to create the tables in BIANA called "ExternalEntityOntology" and "ExternalEntityOntology_isA".
The last one reports the hierarchy of the elements of SCOP. So, you can find the higher categories for concrete external entities.


20.3) Modify the parser

I modified the parser line 153:

        scop_des_fd = file(self.input_file+"dir.des.scope."+self.sourcedb_version.replace("\"","")+"-stable.txt",'r')

And the parser line 99:

        scop_dir_cla_fd = file(self.input_file+"dir.cla.scope."+self.sourcedb_version.replace("\"","")+"-stable.txt",'r')

I have also added some comments explaining parts of the code.


20.4) Parse the database

$> /soft/devel/python-2.7/bin/python parse_database.py scop --input-identifier=/home/quim/Databases/scop/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="SCOP" --database-version="2.06" --promiscuous

Parsing time: 35.8830621243 seconds = less than a minute


20.5) Add the modified parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/scopParser.py .

And now we can add and commit the changes:

$> git add scopParser.py

$> git commit -m "Change in the handling of the database files"

And push it to the web repository:

$> git push -u origin master



-----------------------
21. PARSING OF DRUGBANK
-----------------------

The purpose is to: 

- Create a DrugBank parser for BIANA
- Parse the database
- Add the parser to Github
- Change the manual


21.1) Create a DrugBank parser for BIANA

Proof version:

$> /soft/devel/python-2.7/bin/python parse_database.py drugbank --input-identifier=/home/quim/Databases/DrugBank/drugbank_proof.xml --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DrugBank" --database-version="Release 2017_01 of 01-Jan-2017"

Real version

$> /soft/devel/python-2.7/bin/python parse_database.py drugbank --input-identifier=/home/quim/Databases/DrugBank/full_database.xml --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DrugBank" --database-version="Release 2017_01 of 01-Jan-2017"

Parsing time: 419.690786839 seconds = 7 minutes

It seems to work fine. I have implemented several things, such as:

- I have included the new tables ATC, TargetID, DrugBankID. They do not get removed if they are already created
- I parse first all the information of the individual drugs and then all the drug-drug interactions information for all the drugs
  - If one interaction between two drugs has been already parsed, it checks that if it is different and if not, it is skipped
- I have changed the dict drug_to_interactions in order to include more than one type of DDIs for two drugs
- I have checked that the relation with the interactions works fine. For example:

# Know the externalEntityID of Haloperidol (DB00502)
mysql> select * from externalEntityDrugBankID where value = "DB00502";

# Check if it really interacts with Vinecristine (DB00541)
mysql> select * from externalEntityRelationParticipant P1, externalEntityRelationParticipant P2, externalEntityDrugBankID D where P1.externalEntityRelationID = P2.externalEntityRelationID and P1.externalEntityID != P2.externalEntityID and P2.externalEntityID = D.externalEntityID and P1.externalEntityID = 15569 and D.value = "DB00541";

# Check if it interacts with the target "DRD1_HUMAN"
mysql> select * from externalEntityRelationParticipant P1, externalEntityRelationParticipant P2, externalEntityUniprotEntry D where P1.externalEntityRelationID = P2.externalEntityRelationID and P1.externalEntityID != P2.externalEntityID and P2.externalEntityID = D.externalEntityID and P1.externalEntityID = 15812 and D.value = "DRD2_HUMAN";

21.2) Add the modified parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/drugbankParser.py .

And now we can add and commit the changes:

$> git add drugbankParser.py

$> git commit -m "New DrugBank parser for BIANA. Adapted from the DrugBank parser of Emre Güney"

And push it to the web repository:

$> git push -u origin master



-------------------
22. PARSING OF DCDB
-------------------

The purpose is to: 

- Create a DCDB parser for BIANA
- Parse the database
- Add the parser to Github
- Change the manual


22.1) Create a DCDB parser for BIANA

Real version

$> /soft/devel/python-2.7/bin/python parse_database.py dcdb --input-identifier=/home/quim/Databases/DCDB/DCDB2_plaintxt/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DCDB" --database-version="v2.0"

CAUTION!!! I have detected the problem that if you parse badly and do not reset the database, the external entities remain there and are not removed!!

Parsing time: 3.67 seconds

22.2) Add the parser to Github

We can check if there are changes in our repository by using the "pull" command:

$> git pull origin master

There are no changes. 

Now, we will add the modified parser to the local repository:

$> cd /home/quim/biana_git/biana/BianaParser
$> cp /home/quim/BIANA/biana/BianaParser/dcdbParser.py .

And now we can add and commit the changes:

$> git add dcdbParser.py

$> git commit -m "New DCDB parser for BIANA"

And push it to the web repository:

$> git push -u origin master



----------------------------
W. PARSING OF BIANA_JAN_2017
----------------------------

The purpose is to: 

- Parse the parsers that are already correct to the new database
- Keep checking that the parsers and the tables are correct


W.1) Parsing of IntAct

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/intact/ --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="IntAct" --database-version="Release 2016_10 of 06-Oct-2016" --default-attribute="intact"

Time: Total time: 8220.94 seconds

Checking:
- I have found some "0" entries in GI
- I have found all "0" entries in WormBaseGeneID
- I have found 2 RefSeq ids in AccessionNumber


W.2) Parsing of HPRD

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/hprd/PSIMI_XML --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HPRD" --database-version="Release 2010_04 of 13-Apr-2010" --default-attribute="hprd"

Time: Total time: 630.12640214 seconds

Checking:
- Same problems as IntAct


W.3) Parsing of Reactome

$> /soft/devel/python-2.7/bin/python parse_database.py biopax_level_2 --input-identifier=/home/quim/Databases/reactome/biopax2/ --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Reactome" --database-version="v58 (05-Oct-2016)" --default-attribute="reactome"

Time: Total time: 1620.23863888 seconds

Checking:
- Good Reactome codes
- Problems in GI as well for 0 entries


W.4) Parsing of Taxonomy

$> /soft/devel/python-2.7/bin/python parse_database.py taxonomy --input-identifier=/home/quim/Databases/taxonomy/taxdump/ --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Taxonomy" --database-version="Release 2016_12 of 12-Dec-2016"

Time: Total time: 7530.85074401 seconds

Checking:
- TaxID, TaxID_category, TaxID_name correct
- Number of databases correct


W.5) Parsing of iRefIndex

$> /soft/devel/python-2.7/bin/python parse_database.py irefindex --input-identifier=/home/quim/Databases/irefindex/All.mitab.04072015.txt --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="iRefIndex" --database-version="14.0 (last edited in 2016-07-23)"

Time: Total time: 1104.26533198 seconds

Checking:
- Number of databases correct
- Some externalEntityGI have value 0
- The rest seems to be OK


W.6) Parsing of COG

$> /soft/devel/python-2.7/bin/python parse_database.py cog --input-identifier=/home/quim/Databases/cog2014/ --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="COG" --database-version="2014 update" --promiscuous

Time: Total time: 2043.24625015 seconds

Checking:
--> There was one error in the parser. It has been added again at GitHub corrected
- Number of databases correct
- All the fields seem to be correct


W.7) Parsing of BioGRID

$> /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/biogrid/BIOGRID-ORGANISM-3.4.143.psi25/ --biana-dbname="BIANA_JAN_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="BioGrid" --database-version="Release 3.4.143 (25-Nov-2016)" --default-attribute="biogrid"

Time: Total time: 3332.35186386 seconds = 55 min

Checking:
- Number of databases correct
- Some gene names (AT3G61380, CAC2...) are added in the table externalEntityName which may not be the most appropriate. It would be better in GeneSymbol (which is empty) or depending on the entry, in AccessionNumber (also without entries in this database)
  (SELECT * FROM externalEntityName G, externalEntity E WHERE E.externalEntityID = G.externalEntityID AND E.externalDatabaseID = 9 limit 1000;)
- I have found all "0" entries in WormBaseGeneID

It could be good to check the cross reference different types in psi-mi files. Maybe they have changed.
And check this problem with Names and with WormBase


------------------
X. PARSING SUMMARY
------------------

STRING
------
- Version:		v10
- Time:
- Command: /soft/devel/python-2.7/bin/python parse_database.py stringV10 --input-identifier="/home/quim/Databases/string/" --biana-dbname="test_2017" --biana-dbuser="quim" --biana-dbhost="localhost" --time-control --database-name="STRING" --database-version="v10"
- Command final: /soft/devel/python-2.7/bin/python parse_database.py stringV10 --input-identifier="/home/quim/Databases/string/" --biana-dbname="BIANA_JAN_2017" --biana-dbuser="quim" --biana-dbhost="localhost" --time-control --database-name="STRING" --database-version="v10"
- Added to github: no
- Modified manual: yes (except time)

HPRD
----
- Version:		April_2010
- Time:			412.44 seconds = 7 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/hprd/PSIMI_XML --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HPRD" --database-version="Release 2010_04 of 13-Apr-2010" --default-attribute="hprd"
- Website: www.hprd.org
- Download: HPRD\_PSIMI\_xxxxxx.tar.gz. Untar and unzip the file
- Added to github: yes
- Modified manual: yes

INTACT
------
- Version:		October_2010
- Time:			8202.41169906 seconds = 136 minutes = 2 hours 15 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/intact/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="IntAct" --database-version="Release 2016_10 of 06-Oct-2016" --default-attribute="intact"
- Website: http://www.ebi.ac.uk/intact/
- Download: all xml files in ftp://ftp.ebi.ac.uk/pub/databases/intact/current/psi25/species/
- Added to github: yes
- Modified manual: yes

BIOGRID
-------
- Version:		3.4.143 (25th of November of 2016)
- Time:			3101.04 seconds = 50 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/biogrid/BIOGRID-ORGANISM-3.4.143.psi25/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="BioGrid" --database-version="Release 3.4.143 (25-Nov-2016)" --default-attribute="biogrid"
- Website: https://thebiogrid.org/download.php
- Download: BIOGRID-ORGANISM-x.x.xx.psi25.zip. It is necessary to uncompress manually the zip file (unzip BIOGRID-ORGANISM-x.x.xx.psi25.zip)
- Added to github: yes
- Modified manual: yes

DIP
---
- Version:		Release 2016_07 of 31-Jul-2016
- Time:			152.85 seconds = 150 seconds
- Command: /soft/devel/python-2.7/bin/python parse_database.py psi_mi_2.5 --input-identifier=/home/quim/Databases/dip/dip20160731.mif25 --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DIP" --database-version="Release 2016_07 of 31-Jul-2016" --default-attribute="dip"
- Website: http://dip.doe-mbi.ucla.edu/dip/Download.cgi
- Download: FULL file from downloads, which is complete DIP dataset (file dipxxxxxxxx.mif25.gz)
- Added to github: yes
- Modified manual: yes

MINT
----
- Not available
- Modified manual: yes

REACTOME
--------
- Version:		v58 (October 5, 2016)
- Time:			1269.17 seconds = 21 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py biopax_level_2 --input-identifier=/home/quim/Databases/reactome/biopax2/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Reactome" --database-version="v58 (05-Oct-2016)" --default-attribute="reactome"
- Website: http://www.reactome.org/pages/download-data/
- Download: ``Events in the BioPAX Level 2 format'' file. Uncompress this file
- Added to github: yes
- Modified manual: yes

GO
--
- Version:		1.2 (December 8, 2016)
- Time:			1 minute
- Command: /soft/devel/python-2.7/bin/python parse_database.py go_obo --input-identifier=/home/quim/Databases/go/gene_ontology_edit.obo --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="GO" --database-version="VERSION 1.2 (December 8, 2016)"
- Website: http://www.geneontology.org/ontology/gene_ontology_edit.obo
- Download: gene_ontology_edit.obo
- Added to github: yes
- Modified manual: yes

PSI-MI-OBO
----------
- Version:		1.2 (October 22, 2014)
- Time:			1 second
- Command: /soft/devel/python-2.7/bin/python parse_database.py psi_mi_obo --input-identifier=/home/quim/Databases/psi_mi_obo/psi-mi.obo --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="PSI-MI Obo" --database-version="VERSION 1.2 (October 22, 2014)"
- Website: http://www.psidev.info/node/60
- Download: psi-mi.obo
- Added to github: yes
- Modified manual: yes

TAXONOMY
--------
- Version:		Release 2016_12 of 12-Dec-2016
- Time:			7530 seconds = 125 minutes = 2h 5min
- Command: /soft/devel/python-2.7/bin/python parse_database.py taxonomy --input-identifier=/home/quim/Databases/taxonomy/taxdump/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="Taxonomy" --database-version="Release 2016_12 of 12-Dec-2016"
- Website: ftp://ftp.ncbi.nih.gov/pub/taxonomy/
- Download: taxdump.tar.Z (uncompress)
- Added to github: yes
- Modified manual: yes

IPI
---
- Version:		Release 2011_09 of 27-Sep-2011
- Time:			10 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py ipi --input-identifier=/home/quim/Databases/ipi/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="ipi" --database-version="Release 2011_09 of 27-Sep-2011"
- Website: ftp://ftp.ebi.ac.uk/pub/databases/IPI/last_release/current/
- Download: All the files in the ftp site, using the "ftp_ipi" script
- Added to github: yes
- Modified manual: yes

COG 2014
--------
- Version:		2014 (with some modifications of 18-Oct-2016)
- Time:			27 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py cog --input-identifier=/home/quim/Databases/cog2014/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="COG" --database-version="2014 update" --promiscuous
- Website: ftp://ftp.ncbi.nih.gov/pub/COG/COG2014/data/
- Download: prot2003-2014.fa, prot2003-2014.tab, genomes2003-2014.tab, fun2003-2014.tab, cognames2003-2014.tab, cog2003-2014.csv, prot2003-2014.gi2gbk.tab
- Added to github: yes
- Modified manual: yes

HGNC
----
- Version:		Release 2016_12 of 13-Dec-2016
- Time:			30 seconds
- Command: /soft/devel/python-2.7/bin/python parse_database.py hgnc_2016 --input-identifier=/home/quim/Databases/hgnc/hgnc_complete_set.txt --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="HGNC" --database-version="Release 2016_12 of 13-Dec-2016"
- Website: http://www.genenames.org/cgi-bin/statistics
- Download: hgnc complete set.txt
- Added to github: yes
- Modified manual: yes

IREFINDEX
---------
- Version:		14.0 (last edited in 2016-07-23)
- Time:			15 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py irefindex --input-identifier=/home/quim/Databases/irefindex/All.mitab.04072015.txt --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="iRefIndex" --database-version="14.0 (last edited in 2016-07-23)"
- Website: http://irefindex.org/download/irefindex/data/archive/release_14.0/psi_mitab/MITAB2.6/
- Download: File All.mitab.??????.txt.zip
- Added to github: yes
- Modified manual: yes

SCOP
----
- Version:		2.06
- Time:			less than a minute
- Command: /soft/devel/python-2.7/bin/python parse_database.py scop --input-identifier=/home/quim/Databases/scop/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="SCOP" --database-version="2.06" --promiscuous
- Website: http://scop.berkeley.edu/downloads/
- Download: The parsable SCOPe files "dir.cla.scope.version-stable.txt" and "dir.des.scope.version-stable.txt"
- Added to github: yes
- Modified manual: yes

DRUGBANK
--------
- Version:		5.0 (update 2017-01-09)
- Time:			7 minutes
- Command: /soft/devel/python-2.7/bin/python parse_database.py drugbank --input-identifier=/home/quim/Databases/DrugBank/full_database.xml --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DrugBank" --database-version="Release 2017_01 of 01-Jan-2017"
- Download: "full database.xml"
- Added to github: yes
- Modified manual: yes

DCDB
----
- Version:		2.0
- Time:			3 seconds
- Command: /soft/devel/python-2.7/bin/python parse_database.py dcdb --input-identifier=/home/quim/Databases/DCDB/DCDB2_plaintxt/ --biana-dbname="test_2017" --biana-dbhost="localhost" --biana-dbuser="quim" --time-control --database-name="DCDB" --database-version="v2.0"
- Download: "DCDB2_plaintxt.zip" (uncompress)
- Added to github: yes
- Modified manual: yes

DATABASE
--------
- Version:		
- Time:			
- Command: 
- Website:
- Download:
- Added to github: 
- Modified manual: 





TO DO
-----

- PARSE STRING V10 (now parsing)
- Add String to github
- Add PFAM!!

- Work in Uniprot parser (add the new external databases cross-references)
- Work in the parsers of the new external databases

Order of time:

STRING (????) > PFAM (????) > Uniprot Swiss (1 day) > IntAct (2h 15 min) > Taxonomy (2h 5 min) > BioGRID (50 min) > COG (27 min) > Reactome (21 min) > iRefIndex (15 min) > IPI (10 min) > HPRD (7 min) > DrugBank (7 min) > DIP (3 min) > SCOP (1 min) > HGNC (1 min) > GO (1 min) > PSI-MI-OBO (1 min)

Missing:

STRING (????) > PFAM (????) > Uniprot Swiss (1 day) > IPI (10 min) > DrugBank (7 min) > DIP (3 min) > SCOP (1 min) > HGNC (1 min) > GO (1 min) > PSI-MI-OBO (1 min)

